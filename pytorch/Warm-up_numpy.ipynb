{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-14T22:28:41.298751700Z",
     "start_time": "2024-02-14T22:28:41.098248900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28941888.2903891\n",
      "1 26592034.862033214\n",
      "2 28193212.179164015\n",
      "3 29333673.666476343\n",
      "4 26771884.854327887\n",
      "5 20218341.013178155\n",
      "6 12661029.948719759\n",
      "7 6974211.9949134495\n",
      "8 3736679.5554723255\n",
      "9 2125513.8786284714\n",
      "10 1347448.0555756784\n",
      "11 953085.8284064902\n",
      "12 732404.5462561375\n",
      "13 593560.9911913229\n",
      "14 496430.0927308339\n",
      "15 423047.2893706238\n",
      "16 364879.95916152187\n",
      "17 317319.43318261096\n",
      "18 277789.00783888844\n",
      "19 244492.8157174144\n",
      "20 216210.52569681683\n",
      "21 192030.26455266506\n",
      "22 171198.78280751157\n",
      "23 153175.80301703984\n",
      "24 137508.7771000133\n",
      "25 123825.0424656576\n",
      "26 111825.93277440229\n",
      "27 101256.51023143646\n",
      "28 91937.23581462004\n",
      "29 83679.18713478258\n",
      "30 76334.11144038086\n",
      "31 69775.86823203487\n",
      "32 63909.931415881576\n",
      "33 58644.98123269838\n",
      "34 53910.03494298072\n",
      "35 49643.213981815374\n",
      "36 45786.172724889635\n",
      "37 42294.1755689638\n",
      "38 39124.749065921\n",
      "39 36248.08794274322\n",
      "40 33627.403665113685\n",
      "41 31234.13069371683\n",
      "42 29044.27632025287\n",
      "43 27036.994875234323\n",
      "44 25195.40736793319\n",
      "45 23502.890828284428\n",
      "46 21944.772138599248\n",
      "47 20508.93348817752\n",
      "48 19183.88157137149\n",
      "49 17960.060267874942\n",
      "50 16828.388612774488\n",
      "51 15780.273389021655\n",
      "52 14808.831987835774\n",
      "53 13907.708955516504\n",
      "54 13069.90535174554\n",
      "55 12290.157017605283\n",
      "56 11564.211474348609\n",
      "57 10887.67148643297\n",
      "58 10257.02100334366\n",
      "59 9668.897338950528\n",
      "60 9119.438265016885\n",
      "61 8605.702523456912\n",
      "62 8125.063283714755\n",
      "63 7675.244567040493\n",
      "64 7253.816738567059\n",
      "65 6858.6130295661005\n",
      "66 6487.824058802301\n",
      "67 6139.620587642294\n",
      "68 5812.485653417625\n",
      "69 5504.891852255806\n",
      "70 5215.524051660232\n",
      "71 4943.084600379905\n",
      "72 4686.567567668245\n",
      "73 4445.043646513721\n",
      "74 4217.403658558367\n",
      "75 4002.5324894509613\n",
      "76 3799.9529084125097\n",
      "77 3608.717387609638\n",
      "78 3428.067446525196\n",
      "79 3257.484163434747\n",
      "80 3096.2119035812216\n",
      "81 2943.7117493889864\n",
      "82 2799.5085097322253\n",
      "83 2663.0168366941434\n",
      "84 2533.8303966832223\n",
      "85 2411.52140110008\n",
      "86 2295.8279933396097\n",
      "87 2186.1306754779885\n",
      "88 2082.1754859001603\n",
      "89 1983.56621259916\n",
      "90 1890.0739415666662\n",
      "91 1801.3970107754185\n",
      "92 1717.1553518486462\n",
      "93 1637.2176654584716\n",
      "94 1561.269804890486\n",
      "95 1489.1365780291067\n",
      "96 1420.5908064915725\n",
      "97 1355.4305372591607\n",
      "98 1293.5274079294982\n",
      "99 1234.640410508649\n",
      "100 1178.6126524463625\n",
      "101 1125.3696143269049\n",
      "102 1074.753610242995\n",
      "103 1026.5623571043552\n",
      "104 980.6730437160206\n",
      "105 937.0144177080444\n",
      "106 895.4332062639478\n",
      "107 855.7964726500934\n",
      "108 818.0393513782326\n",
      "109 782.0664746123776\n",
      "110 747.8101913924102\n",
      "111 715.1152317029265\n",
      "112 683.9530431468909\n",
      "113 654.2384997358763\n",
      "114 625.8963606889286\n",
      "115 598.859054875596\n",
      "116 573.0648587581614\n",
      "117 548.4465978335569\n",
      "118 524.975848181857\n",
      "119 502.61148727210536\n",
      "120 481.25827375810707\n",
      "121 460.8621177489621\n",
      "122 441.38493952878196\n",
      "123 422.77746291619576\n",
      "124 405.0012022374681\n",
      "125 388.0227757058676\n",
      "126 371.80025173588797\n",
      "127 356.29167986535515\n",
      "128 341.4636949782464\n",
      "129 327.2896655359913\n",
      "130 313.73804836210525\n",
      "131 300.777047244253\n",
      "132 288.3811079786103\n",
      "133 276.5353585148772\n",
      "134 265.1984905599379\n",
      "135 254.34745530127066\n",
      "136 243.962806145026\n",
      "137 234.02301345611352\n",
      "138 224.51114556067589\n",
      "139 215.4079369960138\n",
      "140 206.69452814855185\n",
      "141 198.34765945211353\n",
      "142 190.35667697836828\n",
      "143 182.70284329592866\n",
      "144 175.37363654805984\n",
      "145 168.35186354831887\n",
      "146 161.62507960870357\n",
      "147 155.18446479398307\n",
      "148 149.01105403095517\n",
      "149 143.09554042426686\n",
      "150 137.4251831266915\n",
      "151 131.9894585393172\n",
      "152 126.77796992995874\n",
      "153 121.78347185398766\n",
      "154 116.99468194149473\n",
      "155 112.40127957683544\n",
      "156 107.99763911627107\n",
      "157 103.77376429885555\n",
      "158 99.72258675601796\n",
      "159 95.83673902331542\n",
      "160 92.10977905406412\n",
      "161 88.53321515245868\n",
      "162 85.10117337842573\n",
      "163 81.80920868469562\n",
      "164 78.64960799937111\n",
      "165 75.61714332021036\n",
      "166 72.70600536166344\n",
      "167 69.91258638703954\n",
      "168 67.22949250892012\n",
      "169 64.65409377697509\n",
      "170 62.18112933572509\n",
      "171 59.807242936116346\n",
      "172 57.52664433558054\n",
      "173 55.33765444029399\n",
      "174 53.2347666935545\n",
      "175 51.214946634871666\n",
      "176 49.27459538205798\n",
      "177 47.41023356247383\n",
      "178 45.61936669055519\n",
      "179 43.89971626529382\n",
      "180 42.24716894897202\n",
      "181 40.65824519501\n",
      "182 39.13082510294234\n",
      "183 37.66329182587904\n",
      "184 36.25321646922717\n",
      "185 34.89780242514799\n",
      "186 33.59571647492779\n",
      "187 32.343070761377135\n",
      "188 31.1390368639791\n",
      "189 29.981557074665822\n",
      "190 28.86829304312907\n",
      "191 27.797698891273086\n",
      "192 26.768630351967182\n",
      "193 25.778348776427787\n",
      "194 24.82641959790653\n",
      "195 23.910846321435073\n",
      "196 23.02970467349266\n",
      "197 22.181923391082265\n",
      "198 21.36703820058002\n",
      "199 20.582519900198903\n",
      "200 19.827476584651336\n",
      "201 19.101083894867745\n",
      "202 18.4021731778466\n",
      "203 17.72966757738972\n",
      "204 17.082703784437832\n",
      "205 16.45987585435802\n",
      "206 15.860235833654656\n",
      "207 15.283109439816208\n",
      "208 14.727680273675949\n",
      "209 14.192964440037734\n",
      "210 13.678554385442904\n",
      "211 13.18318644617406\n",
      "212 12.706031405535267\n",
      "213 12.246710958553935\n",
      "214 11.804404930282313\n",
      "215 11.378450314223038\n",
      "216 10.968415723886517\n",
      "217 10.573533193545387\n",
      "218 10.193145243989319\n",
      "219 9.82681398254974\n",
      "220 9.47390658561169\n",
      "221 9.134068857103347\n",
      "222 8.806742061932141\n",
      "223 8.491458604391312\n",
      "224 8.187725997164282\n",
      "225 7.895035418940702\n",
      "226 7.613199673423404\n",
      "227 7.3417101943821965\n",
      "228 7.08009028702727\n",
      "229 6.827970910722995\n",
      "230 6.584994343895077\n",
      "231 6.350887168427276\n",
      "232 6.125234725618023\n",
      "233 5.907832612267406\n",
      "234 5.69833892595754\n",
      "235 5.496394401176551\n",
      "236 5.3017815345175645\n",
      "237 5.114262386359114\n",
      "238 4.933495961061988\n",
      "239 4.759206049978621\n",
      "240 4.591273753655674\n",
      "241 4.42932844361783\n",
      "242 4.273249630220372\n",
      "243 4.122822961365852\n",
      "244 3.9777754344452894\n",
      "245 3.837935636061779\n",
      "246 3.703081475150463\n",
      "247 3.5730902160388545\n",
      "248 3.447697042235359\n",
      "249 3.3268172635175146\n",
      "250 3.210238617094456\n",
      "251 3.097827670388174\n",
      "252 2.9894640028042465\n",
      "253 2.884955326205204\n",
      "254 2.784131995268089\n",
      "255 2.686913897554134\n",
      "256 2.5931254403373485\n",
      "257 2.5027023818617513\n",
      "258 2.4154829974818335\n",
      "259 2.331364069303162\n",
      "260 2.2502653851383987\n",
      "261 2.1720078220849963\n",
      "262 2.0964849540908457\n",
      "263 2.0236478918265037\n",
      "264 1.9533767407024212\n",
      "265 1.885604613126036\n",
      "266 1.8202086680489926\n",
      "267 1.75712776996031\n",
      "268 1.6962720919157463\n",
      "269 1.6375428136306784\n",
      "270 1.5808721642072086\n",
      "271 1.526218716075106\n",
      "272 1.4734677855684848\n",
      "273 1.4225659742969592\n",
      "274 1.37346722975265\n",
      "275 1.3260691794282327\n",
      "276 1.2803506290120998\n",
      "277 1.2362480758965522\n",
      "278 1.1936749169068075\n",
      "279 1.1525719456257737\n",
      "280 1.1129001370549323\n",
      "281 1.0746227137201565\n",
      "282 1.0376773062211802\n",
      "283 1.0020223538812096\n",
      "284 0.967610582849081\n",
      "285 0.9344025801773548\n",
      "286 0.9023381912047117\n",
      "287 0.8713934531403074\n",
      "288 0.8415245322458698\n",
      "289 0.8126927417633478\n",
      "290 0.7848715066741406\n",
      "291 0.758000035137586\n",
      "292 0.7320642466774153\n",
      "293 0.7070312412519202\n",
      "294 0.6828652169356977\n",
      "295 0.6595508353334854\n",
      "296 0.637026877788075\n",
      "297 0.6152829279773803\n",
      "298 0.5942880419218698\n",
      "299 0.5740157252345941\n",
      "300 0.5544437471767927\n",
      "301 0.5355505256328998\n",
      "302 0.5173086389448527\n",
      "303 0.4997016912581954\n",
      "304 0.4826911279152362\n",
      "305 0.466268181898705\n",
      "306 0.4504107212970613\n",
      "307 0.43510098942396946\n",
      "308 0.42031626036313186\n",
      "309 0.4060393828766175\n",
      "310 0.3922540296069029\n",
      "311 0.3789407958930404\n",
      "312 0.3660875385291165\n",
      "313 0.3536796350308591\n",
      "314 0.34168915162761637\n",
      "315 0.3301079761882394\n",
      "316 0.3189255843926178\n",
      "317 0.3081268433075882\n",
      "318 0.297694678652378\n",
      "319 0.2876215924427985\n",
      "320 0.27789282029732065\n",
      "321 0.26849658707991186\n",
      "322 0.2594194001047658\n",
      "323 0.25065417538648005\n",
      "324 0.24218657588033088\n",
      "325 0.23400818927654526\n",
      "326 0.22610856954749683\n",
      "327 0.21847818807491282\n",
      "328 0.211107896836591\n",
      "329 0.2039876397847074\n",
      "330 0.1971109109617124\n",
      "331 0.1904740737101288\n",
      "332 0.18405694606162817\n",
      "333 0.17785779756249412\n",
      "334 0.17186972081534058\n",
      "335 0.16608364197891248\n",
      "336 0.16049460081550246\n",
      "337 0.15509666614537904\n",
      "338 0.14988226896054396\n",
      "339 0.14484311540311237\n",
      "340 0.1399753430157073\n",
      "341 0.13527278818162902\n",
      "342 0.13072914541512756\n",
      "343 0.12633990512143933\n",
      "344 0.12209909064560742\n",
      "345 0.11800187773067425\n",
      "346 0.11404318715020559\n",
      "347 0.11021752384170672\n",
      "348 0.10652198414774006\n",
      "349 0.10295392167376212\n",
      "350 0.09950416339471602\n",
      "351 0.09617099378827514\n",
      "352 0.09295031906102702\n",
      "353 0.08983809776645543\n",
      "354 0.08683058310899217\n",
      "355 0.08392530196948636\n",
      "356 0.08111716656404647\n",
      "357 0.07840379295369666\n",
      "358 0.07578211813976268\n",
      "359 0.07324904706506968\n",
      "360 0.0708012313638855\n",
      "361 0.06843583303227167\n",
      "362 0.06614993597406968\n",
      "363 0.06394076913157105\n",
      "364 0.06180578998402549\n",
      "365 0.059742870277347676\n",
      "366 0.05774927382482131\n",
      "367 0.055822999013899297\n",
      "368 0.05396158757851919\n",
      "369 0.052162217808235364\n",
      "370 0.05042313181128374\n",
      "371 0.04874259499655191\n",
      "372 0.047118180443435326\n",
      "373 0.04554843176019835\n",
      "374 0.044031571674582395\n",
      "375 0.042565211671601044\n",
      "376 0.04114813566555688\n",
      "377 0.039778573084380195\n",
      "378 0.03845477100825407\n",
      "379 0.03717529515804395\n",
      "380 0.035938928932424216\n",
      "381 0.03474379226173331\n",
      "382 0.033588503184318635\n",
      "383 0.03247184598538522\n",
      "384 0.03139270567928906\n",
      "385 0.030349985179345285\n",
      "386 0.029342415747669916\n",
      "387 0.028367808132442454\n",
      "388 0.02742568644547147\n",
      "389 0.02651506061772193\n",
      "390 0.025635147129274657\n",
      "391 0.024784474096868465\n",
      "392 0.023962088701484495\n",
      "393 0.02316716122542775\n",
      "394 0.0223988878573591\n",
      "395 0.02165619308217725\n",
      "396 0.02093828071364757\n",
      "397 0.020244372940900188\n",
      "398 0.019573470560528765\n",
      "399 0.018924900153255115\n",
      "400 0.018297985982741995\n",
      "401 0.017691951612258068\n",
      "402 0.017106117608396698\n",
      "403 0.016539782458712023\n",
      "404 0.01599251980891824\n",
      "405 0.015463310650629794\n",
      "406 0.014951609733816023\n",
      "407 0.014456951709202614\n",
      "408 0.013978759686062363\n",
      "409 0.013516629416018737\n",
      "410 0.013069712366849692\n",
      "411 0.012637573875670778\n",
      "412 0.012219904672798638\n",
      "413 0.011816124708148284\n",
      "414 0.01142567511412006\n",
      "415 0.011048218802740782\n",
      "416 0.01068333419501531\n",
      "417 0.01033051940602973\n",
      "418 0.009989387326195292\n",
      "419 0.009659576241277775\n",
      "420 0.009340714198817126\n",
      "421 0.009032518233869139\n",
      "422 0.008734533514830901\n",
      "423 0.008446548938784229\n",
      "424 0.00816795146133285\n",
      "425 0.007898559759156503\n",
      "426 0.007638100410198266\n",
      "427 0.007386269080198671\n",
      "428 0.007142756978462068\n",
      "429 0.006907322735337229\n",
      "430 0.006679713947881175\n",
      "431 0.006459613172042628\n",
      "432 0.00624681682551075\n",
      "433 0.006041065408924653\n",
      "434 0.005842166192899742\n",
      "435 0.0056497919082819535\n",
      "436 0.005463764968953627\n",
      "437 0.005283897832042913\n",
      "438 0.005110009914038826\n",
      "439 0.004941840341696971\n",
      "440 0.004779239652412734\n",
      "441 0.004622045380548806\n",
      "442 0.004470064224693527\n",
      "443 0.004323043758739941\n",
      "444 0.0041808703571417395\n",
      "445 0.004043421321047318\n",
      "446 0.003910504724592227\n",
      "447 0.003781954812462118\n",
      "448 0.003657673556005955\n",
      "449 0.0035374901332698694\n",
      "450 0.0034212544731715734\n",
      "451 0.0033088518927578536\n",
      "452 0.003200172018891826\n",
      "453 0.0030950916949774436\n",
      "454 0.002993442672477013\n",
      "455 0.00289514578873878\n",
      "456 0.0028001218052101616\n",
      "457 0.0027081989959930382\n",
      "458 0.0026193163244879834\n",
      "459 0.002533359587979133\n",
      "460 0.0024502632190540946\n",
      "461 0.0023699053232723545\n",
      "462 0.0022921660824566986\n",
      "463 0.0022169870178289563\n",
      "464 0.0021442894130147376\n",
      "465 0.0020739712832841136\n",
      "466 0.0020059693962517218\n",
      "467 0.0019402273698734174\n",
      "468 0.0018766318429078472\n",
      "469 0.0018151236791696815\n",
      "470 0.0017556432737172102\n",
      "471 0.0016981186936257256\n",
      "472 0.0016424782719252108\n",
      "473 0.0015886753974197923\n",
      "474 0.001536641478100025\n",
      "475 0.0014863258385559813\n",
      "476 0.001437660632786798\n",
      "477 0.00139059272670719\n",
      "478 0.0013450667806927871\n",
      "479 0.0013010610789363631\n",
      "480 0.0012584791071871644\n",
      "481 0.001217301089806303\n",
      "482 0.001177463575762884\n",
      "483 0.0011389383668278785\n",
      "484 0.0011016779496639461\n",
      "485 0.001065639545480499\n",
      "486 0.0010307853183416892\n",
      "487 0.0009970784782704616\n",
      "488 0.0009644745825557876\n",
      "489 0.0009329402967555323\n",
      "490 0.0009024525384056287\n",
      "491 0.0008729528810483196\n",
      "492 0.0008444193215969924\n",
      "493 0.000816825211301776\n",
      "494 0.0007901330410616612\n",
      "495 0.0007643158162932748\n",
      "496 0.0007393470945912329\n",
      "497 0.0007151973134405167\n",
      "498 0.0006918437851573785\n",
      "499 0.0006692509898449787\n"
     ]
    }
   ],
   "source": [
    "# Code in file tensor/two_layer_net_numpy.py\n",
    "import numpy as np\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "  # Forward pass: compute predicted y\n",
    "  h = x.dot(w1)\n",
    "  h_relu = np.maximum(h, 0)\n",
    "  y_pred = h_relu.dot(w2)\n",
    "  \n",
    "  # Compute and print loss\n",
    "  loss = np.square(y_pred - y).sum()\n",
    "  print(t, loss)\n",
    "  \n",
    "  # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "  grad_y_pred = 2.0 * (y_pred - y)\n",
    "  grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "  grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "  grad_h = grad_h_relu.copy()\n",
    "  grad_h[h < 0] = 0\n",
    "  grad_w1 = x.T.dot(grad_h)\n",
    " \n",
    "  # Update weights\n",
    "  w1 -= learning_rate * grad_w1\n",
    "  w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 35918020.0\n",
      "1 42317172.0\n",
      "2 58148144.0\n",
      "3 66652096.0\n",
      "4 49997160.0\n",
      "5 20707976.0\n",
      "6 5838780.5\n",
      "7 2200260.25\n",
      "8 1392803.875\n",
      "9 1091804.125\n",
      "10 903945.5\n",
      "11 761458.375\n",
      "12 647321.875\n",
      "13 554303.5625\n",
      "14 477621.5625\n",
      "15 414041.375\n",
      "16 360946.65625\n",
      "17 316188.25\n",
      "18 278288.1875\n",
      "19 245974.75\n",
      "20 218220.4375\n",
      "21 194207.109375\n",
      "22 173385.125\n",
      "23 155236.40625\n",
      "24 139355.75\n",
      "25 125409.75\n",
      "26 113109.34375\n",
      "27 102255.234375\n",
      "28 92632.75\n",
      "29 84094.171875\n",
      "30 76486.8984375\n",
      "31 69684.7109375\n",
      "32 63585.70703125\n",
      "33 58112.0546875\n",
      "34 53187.24609375\n",
      "35 48744.375\n",
      "36 44733.03515625\n",
      "37 41103.0703125\n",
      "38 37813.296875\n",
      "39 34827.75\n",
      "40 32115.84765625\n",
      "41 29647.66015625\n",
      "42 27398.396484375\n",
      "43 25344.009765625\n",
      "44 23466.466796875\n",
      "45 21749.203125\n",
      "46 20175.01953125\n",
      "47 18731.64453125\n",
      "48 17405.259765625\n",
      "49 16186.4150390625\n",
      "50 15064.0986328125\n",
      "51 14030.23046875\n",
      "52 13077.7734375\n",
      "53 12198.7275390625\n",
      "54 11386.640625\n",
      "55 10635.787109375\n",
      "56 9941.052734375\n",
      "57 9297.3759765625\n",
      "58 8701.1689453125\n",
      "59 8147.72509765625\n",
      "60 7634.07666015625\n",
      "61 7157.26416015625\n",
      "62 6714.0830078125\n",
      "63 6301.83544921875\n",
      "64 5918.126953125\n",
      "65 5560.7734375\n",
      "66 5227.9443359375\n",
      "67 4917.69189453125\n",
      "68 4627.94677734375\n",
      "69 4357.41552734375\n",
      "70 4104.7314453125\n",
      "71 3868.576416015625\n",
      "72 3647.728759765625\n",
      "73 3440.969970703125\n",
      "74 3247.3828125\n",
      "75 3066.095947265625\n",
      "76 2896.282958984375\n",
      "77 2736.98388671875\n",
      "78 2587.620849609375\n",
      "79 2447.399658203125\n",
      "80 2315.660400390625\n",
      "81 2191.88037109375\n",
      "82 2075.5078125\n",
      "83 1966.0810546875\n",
      "84 1863.14794921875\n",
      "85 1766.259033203125\n",
      "86 1674.9915771484375\n",
      "87 1589.001708984375\n",
      "88 1507.9598388671875\n",
      "89 1431.577880859375\n",
      "90 1359.49072265625\n",
      "91 1291.461669921875\n",
      "92 1227.280029296875\n",
      "93 1166.694580078125\n",
      "94 1109.4620361328125\n",
      "95 1055.3779296875\n",
      "96 1004.2322387695312\n",
      "97 955.8563232421875\n",
      "98 910.0770263671875\n",
      "99 866.7562255859375\n",
      "100 825.72314453125\n",
      "101 786.8444213867188\n",
      "102 749.9967651367188\n",
      "103 715.0773315429688\n",
      "104 681.9660034179688\n",
      "105 650.5512084960938\n",
      "106 620.7455444335938\n",
      "107 592.46728515625\n",
      "108 565.620361328125\n",
      "109 540.1143188476562\n",
      "110 515.8798828125\n",
      "111 492.8551025390625\n",
      "112 470.9712829589844\n",
      "113 450.1737060546875\n",
      "114 430.3862609863281\n",
      "115 411.56121826171875\n",
      "116 393.6561279296875\n",
      "117 376.5966491699219\n",
      "118 360.35443115234375\n",
      "119 344.88629150390625\n",
      "120 330.15081787109375\n",
      "121 316.10595703125\n",
      "122 302.71844482421875\n",
      "123 289.9564208984375\n",
      "124 277.7965087890625\n",
      "125 266.1864013671875\n",
      "126 255.10757446289062\n",
      "127 244.54116821289062\n",
      "128 234.45086669921875\n",
      "129 224.8229217529297\n",
      "130 215.62449645996094\n",
      "131 206.8438720703125\n",
      "132 198.44970703125\n",
      "133 190.42630004882812\n",
      "134 182.75668334960938\n",
      "135 175.4244384765625\n",
      "136 168.41561889648438\n",
      "137 161.70980834960938\n",
      "138 155.29928588867188\n",
      "139 149.16445922851562\n",
      "140 143.29241943359375\n",
      "141 137.67141723632812\n",
      "142 132.29312133789062\n",
      "143 127.1412582397461\n",
      "144 122.20771789550781\n",
      "145 117.48641204833984\n",
      "146 112.95849609375\n",
      "147 108.62000274658203\n",
      "148 104.46195983886719\n",
      "149 100.47581481933594\n",
      "150 96.65545654296875\n",
      "151 92.99183654785156\n",
      "152 89.47898864746094\n",
      "153 86.10853576660156\n",
      "154 82.87472534179688\n",
      "155 79.77191925048828\n",
      "156 76.79493713378906\n",
      "157 73.93951416015625\n",
      "158 71.19805908203125\n",
      "159 68.56523895263672\n",
      "160 66.03692626953125\n",
      "161 63.607696533203125\n",
      "162 61.27493667602539\n",
      "163 59.03371810913086\n",
      "164 56.882972717285156\n",
      "165 54.813323974609375\n",
      "166 52.824798583984375\n",
      "167 50.91339111328125\n",
      "168 49.07611846923828\n",
      "169 47.310096740722656\n",
      "170 45.61323165893555\n",
      "171 43.980308532714844\n",
      "172 42.41023635864258\n",
      "173 40.89964294433594\n",
      "174 39.446388244628906\n",
      "175 38.047454833984375\n",
      "176 36.7027473449707\n",
      "177 35.40765380859375\n",
      "178 34.16074752807617\n",
      "179 32.96123504638672\n",
      "180 31.806413650512695\n",
      "181 30.694475173950195\n",
      "182 29.623977661132812\n",
      "183 28.592933654785156\n",
      "184 27.59956932067871\n",
      "185 26.64288330078125\n",
      "186 25.721675872802734\n",
      "187 24.835254669189453\n",
      "188 23.979753494262695\n",
      "189 23.155080795288086\n",
      "190 22.36064910888672\n",
      "191 21.595027923583984\n",
      "192 20.857240676879883\n",
      "193 20.14633560180664\n",
      "194 19.460617065429688\n",
      "195 18.799320220947266\n",
      "196 18.16168975830078\n",
      "197 17.54705810546875\n",
      "198 16.954246520996094\n",
      "199 16.382675170898438\n",
      "200 15.831019401550293\n",
      "201 15.298788070678711\n",
      "202 14.785589218139648\n",
      "203 14.290681838989258\n",
      "204 13.813028335571289\n",
      "205 13.351513862609863\n",
      "206 12.906498908996582\n",
      "207 12.47705078125\n",
      "208 12.062681198120117\n",
      "209 11.662720680236816\n",
      "210 11.276189804077148\n",
      "211 10.90329360961914\n",
      "212 10.543525695800781\n",
      "213 10.195974349975586\n",
      "214 9.860492706298828\n",
      "215 9.536070823669434\n",
      "216 9.222992897033691\n",
      "217 8.92099666595459\n",
      "218 8.629030227661133\n",
      "219 8.346936225891113\n",
      "220 8.074373245239258\n",
      "221 7.811173439025879\n",
      "222 7.557011604309082\n",
      "223 7.311321258544922\n",
      "224 7.073896884918213\n",
      "225 6.844416618347168\n",
      "226 6.622755527496338\n",
      "227 6.4083943367004395\n",
      "228 6.201379299163818\n",
      "229 6.001317024230957\n",
      "230 5.807842254638672\n",
      "231 5.62086296081543\n",
      "232 5.440167427062988\n",
      "233 5.2655253410339355\n",
      "234 5.096461296081543\n",
      "235 4.932953834533691\n",
      "236 4.775113105773926\n",
      "237 4.622408866882324\n",
      "238 4.474876880645752\n",
      "239 4.332135200500488\n",
      "240 4.193819046020508\n",
      "241 4.060059070587158\n",
      "242 3.93107533454895\n",
      "243 3.806119441986084\n",
      "244 3.6852307319641113\n",
      "245 3.5682945251464844\n",
      "246 3.455172300338745\n",
      "247 3.3457753658294678\n",
      "248 3.239990711212158\n",
      "249 3.1375374794006348\n",
      "250 3.0384509563446045\n",
      "251 2.942566156387329\n",
      "252 2.849841594696045\n",
      "253 2.760087013244629\n",
      "254 2.6732165813446045\n",
      "255 2.589212656021118\n",
      "256 2.507974624633789\n",
      "257 2.429229736328125\n",
      "258 2.35310697555542\n",
      "259 2.2793266773223877\n",
      "260 2.2080466747283936\n",
      "261 2.138909339904785\n",
      "262 2.072173595428467\n",
      "263 2.0074563026428223\n",
      "264 1.9448003768920898\n",
      "265 1.8841338157653809\n",
      "266 1.8255418539047241\n",
      "267 1.768651008605957\n",
      "268 1.7135288715362549\n",
      "269 1.660261869430542\n",
      "270 1.6087136268615723\n",
      "271 1.5586888790130615\n",
      "272 1.5103745460510254\n",
      "273 1.4635610580444336\n",
      "274 1.4181387424468994\n",
      "275 1.3742945194244385\n",
      "276 1.3317339420318604\n",
      "277 1.2905880212783813\n",
      "278 1.2506426572799683\n",
      "279 1.2120442390441895\n",
      "280 1.1746505498886108\n",
      "281 1.1383442878723145\n",
      "282 1.1032795906066895\n",
      "283 1.0692098140716553\n",
      "284 1.0363645553588867\n",
      "285 1.004347324371338\n",
      "286 0.9735147356987\n",
      "287 0.943573534488678\n",
      "288 0.9145869612693787\n",
      "289 0.8864701986312866\n",
      "290 0.8593242168426514\n",
      "291 0.8328995704650879\n",
      "292 0.8073577880859375\n",
      "293 0.7826189994812012\n",
      "294 0.7586065530776978\n",
      "295 0.7353693246841431\n",
      "296 0.7128866910934448\n",
      "297 0.6910464763641357\n",
      "298 0.6699333786964417\n",
      "299 0.6494580507278442\n",
      "300 0.6296111345291138\n",
      "301 0.6103773713111877\n",
      "302 0.5918049216270447\n",
      "303 0.5737116932868958\n",
      "304 0.556209921836853\n",
      "305 0.539247989654541\n",
      "306 0.5228056907653809\n",
      "307 0.506895899772644\n",
      "308 0.49143508076667786\n",
      "309 0.4764886796474457\n",
      "310 0.461967408657074\n",
      "311 0.44794243574142456\n",
      "312 0.43431785702705383\n",
      "313 0.4211249053478241\n",
      "314 0.4083296060562134\n",
      "315 0.3959301710128784\n",
      "316 0.38391757011413574\n",
      "317 0.3722521960735321\n",
      "318 0.36097198724746704\n",
      "319 0.35004618763923645\n",
      "320 0.33943238854408264\n",
      "321 0.3291340470314026\n",
      "322 0.319163978099823\n",
      "323 0.3094872236251831\n",
      "324 0.3001474142074585\n",
      "325 0.29105475544929504\n",
      "326 0.28225114941596985\n",
      "327 0.27372080087661743\n",
      "328 0.2654368281364441\n",
      "329 0.25743067264556885\n",
      "330 0.24965324997901917\n",
      "331 0.24209412932395935\n",
      "332 0.2348102331161499\n",
      "333 0.22768555581569672\n",
      "334 0.22083301842212677\n",
      "335 0.2141762673854828\n",
      "336 0.20774252712726593\n",
      "337 0.20146812498569489\n",
      "338 0.1954103708267212\n",
      "339 0.1895143687725067\n",
      "340 0.183796226978302\n",
      "341 0.17826876044273376\n",
      "342 0.1729111671447754\n",
      "343 0.16770684719085693\n",
      "344 0.1626657247543335\n",
      "345 0.15776658058166504\n",
      "346 0.15303421020507812\n",
      "347 0.1484236866235733\n",
      "348 0.14397713541984558\n",
      "349 0.13964346051216125\n",
      "350 0.13546685874462128\n",
      "351 0.13137172162532806\n",
      "352 0.1274431198835373\n",
      "353 0.12361841648817062\n",
      "354 0.11991596221923828\n",
      "355 0.11631767451763153\n",
      "356 0.11282886564731598\n",
      "357 0.10946906358003616\n",
      "358 0.10618235915899277\n",
      "359 0.10301459580659866\n",
      "360 0.09992580115795135\n",
      "361 0.09694211930036545\n",
      "362 0.09403775632381439\n",
      "363 0.09124069660902023\n",
      "364 0.08851689100265503\n",
      "365 0.08585981279611588\n",
      "366 0.08329211920499802\n",
      "367 0.08082146942615509\n",
      "368 0.07838968932628632\n",
      "369 0.07606209814548492\n",
      "370 0.07379573583602905\n",
      "371 0.07159719616174698\n",
      "372 0.06944107264280319\n",
      "373 0.06737323105335236\n",
      "374 0.06536699831485748\n",
      "375 0.06341830641031265\n",
      "376 0.06153757870197296\n",
      "377 0.05969901382923126\n",
      "378 0.05792361497879028\n",
      "379 0.056208040565252304\n",
      "380 0.05452773720026016\n",
      "381 0.05290843918919563\n",
      "382 0.0513421967625618\n",
      "383 0.04981548339128494\n",
      "384 0.048342809081077576\n",
      "385 0.0469028539955616\n",
      "386 0.0454956479370594\n",
      "387 0.04417111724615097\n",
      "388 0.042854808270931244\n",
      "389 0.04158348590135574\n",
      "390 0.04034784808754921\n",
      "391 0.03915903717279434\n",
      "392 0.03799409791827202\n",
      "393 0.03688303381204605\n",
      "394 0.03578830510377884\n",
      "395 0.0347307026386261\n",
      "396 0.033714793622493744\n",
      "397 0.0327097550034523\n",
      "398 0.03174545243382454\n",
      "399 0.030807457864284515\n",
      "400 0.0299035906791687\n",
      "401 0.029019968584179878\n",
      "402 0.028172792866826057\n",
      "403 0.02734135463833809\n",
      "404 0.026541829109191895\n",
      "405 0.025761695578694344\n",
      "406 0.02500457689166069\n",
      "407 0.024269282817840576\n",
      "408 0.023565562441945076\n",
      "409 0.02287125214934349\n",
      "410 0.022204071283340454\n",
      "411 0.021554432809352875\n",
      "412 0.020924357697367668\n",
      "413 0.02031792141497135\n",
      "414 0.01972513645887375\n",
      "415 0.019152551889419556\n",
      "416 0.01859809085726738\n",
      "417 0.01805846393108368\n",
      "418 0.01753128506243229\n",
      "419 0.017023175954818726\n",
      "420 0.016528604552149773\n",
      "421 0.01605306565761566\n",
      "422 0.015588262118399143\n",
      "423 0.015137816779315472\n",
      "424 0.014702659100294113\n",
      "425 0.014281025156378746\n",
      "426 0.013875765725970268\n",
      "427 0.013471361249685287\n",
      "428 0.01308857835829258\n",
      "429 0.012709194794297218\n",
      "430 0.012342841364443302\n",
      "431 0.011992137879133224\n",
      "432 0.011649969965219498\n",
      "433 0.011313991621136665\n",
      "434 0.01100311428308487\n",
      "435 0.010692019946873188\n",
      "436 0.010383741930127144\n",
      "437 0.010092398151755333\n",
      "438 0.009802982211112976\n",
      "439 0.009528599679470062\n",
      "440 0.00926010962575674\n",
      "441 0.009003259241580963\n",
      "442 0.00874982587993145\n",
      "443 0.008501538075506687\n",
      "444 0.008265017531812191\n",
      "445 0.008032362908124924\n",
      "446 0.007806139998137951\n",
      "447 0.007588455453515053\n",
      "448 0.0073793018236756325\n",
      "449 0.007169379387050867\n",
      "450 0.0069760591723024845\n",
      "451 0.006779107730835676\n",
      "452 0.006593428552150726\n",
      "453 0.006408549379557371\n",
      "454 0.0062400479800999165\n",
      "455 0.0060651181265711784\n",
      "456 0.005897738970816135\n",
      "457 0.00573709886521101\n",
      "458 0.005580723285675049\n",
      "459 0.005430278368294239\n",
      "460 0.005282189231365919\n",
      "461 0.0051364353857934475\n",
      "462 0.005000451114028692\n",
      "463 0.00486783916130662\n",
      "464 0.004739278927445412\n",
      "465 0.004608729854226112\n",
      "466 0.00448810588568449\n",
      "467 0.004365553148090839\n",
      "468 0.004252653568983078\n",
      "469 0.004139063414186239\n",
      "470 0.004032499622553587\n",
      "471 0.0039256117306649685\n",
      "472 0.003825631458312273\n",
      "473 0.0037238583900034428\n",
      "474 0.003629992250353098\n",
      "475 0.0035356818698346615\n",
      "476 0.003445200389251113\n",
      "477 0.0033539196010679007\n",
      "478 0.0032691825181245804\n",
      "479 0.0031858657021075487\n",
      "480 0.003105652052909136\n",
      "481 0.003026185557246208\n",
      "482 0.0029472061432898045\n",
      "483 0.0028749373741447926\n",
      "484 0.0028047675732523203\n",
      "485 0.0027344562113285065\n",
      "486 0.0026658857241272926\n",
      "487 0.0026016789488494396\n",
      "488 0.0025373068638145924\n",
      "489 0.0024733575992286205\n",
      "490 0.0024130777455866337\n",
      "491 0.0023537627421319485\n",
      "492 0.0022954740561544895\n",
      "493 0.002241597045212984\n",
      "494 0.002187927020713687\n",
      "495 0.002133406698703766\n",
      "496 0.0020820540376007557\n",
      "497 0.0020323526114225388\n",
      "498 0.0019858218729496002\n",
      "499 0.0019369819201529026\n"
     ]
    }
   ],
   "source": [
    "# Code in file tensor/two_layer_net_tensor.py\n",
    "import torch\n",
    "\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda') # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = torch.randn(D_in, H, device=device)\n",
    "w2 = torch.randn(H, D_out, device=device)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "  # Forward pass: compute predicted y\n",
    "  h = x.mm(w1)\n",
    "  h_relu = h.clamp(min=0)\n",
    "  y_pred = h_relu.mm(w2)\n",
    "\n",
    "  # Compute and print loss; loss is a scalar, and is stored in a PyTorch Tensor\n",
    "  # of shape (); we can get its value as a Python number with loss.item().\n",
    "  loss = (y_pred - y).pow(2).sum()\n",
    "  print(t, loss.item())\n",
    "\n",
    "  # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "  grad_y_pred = 2.0 * (y_pred - y)\n",
    "  grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "  grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "  grad_h = grad_h_relu.clone()\n",
    "  grad_h[h < 0] = 0\n",
    "  grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "  # Update weights using gradient descent\n",
    "  w1 -= learning_rate * grad_w1\n",
    "  w2 -= learning_rate * grad_w2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T22:41:59.168949Z",
     "start_time": "2024-02-14T22:41:58.611806800Z"
    }
   },
   "id": "54e0f158e3d9a0eb",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_2), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(1000, 100) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_3), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(100, 10) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[44], line 32\u001B[0m\n\u001B[0;32m     29\u001B[0m loss \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mreduce_sum((y \u001B[38;5;241m-\u001B[39m y_pred) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2.0\u001B[39m)\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# Compute gradient of the loss with respect to w1 and w2.\u001B[39;00m\n\u001B[1;32m---> 32\u001B[0m grad_w1, grad_w2 \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mgradients(loss, [w1, w2])\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# Update the weights using gradient descent. To actually update the weights\u001B[39;00m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# we need to evaluate new_w1 and new_w2 when executing the graph. Note that\u001B[39;00m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# in TensorFlow the the act of updating the value of the weights is part of\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# the computational graph; in PyTorch this happens outside the computational\u001B[39;00m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# graph.\u001B[39;00m\n\u001B[0;32m     39\u001B[0m learning_rate \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1e-6\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:323\u001B[0m, in \u001B[0;36mgradients_v2\u001B[1;34m(ys, xs, grad_ys, name, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;66;03m# Creating the gradient graph for control flow mutates Operations.\u001B[39;00m\n\u001B[0;32m    319\u001B[0m \u001B[38;5;66;03m# _mutation_lock ensures a Session.run call cannot occur between creating and\u001B[39;00m\n\u001B[0;32m    320\u001B[0m \u001B[38;5;66;03m# mutating new ops.\u001B[39;00m\n\u001B[0;32m    321\u001B[0m \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    322\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mget_default_graph()\u001B[38;5;241m.\u001B[39m_mutation_lock():\n\u001B[1;32m--> 323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m gradients_util\u001B[38;5;241m.\u001B[39m_GradientsHelper(\n\u001B[0;32m    324\u001B[0m       ys, xs, grad_ys, name, \u001B[38;5;28;01mTrue\u001B[39;00m, gate_gradients,\n\u001B[0;32m    325\u001B[0m       aggregation_method, stop_gradients,\n\u001B[0;32m    326\u001B[0m       unconnected_gradients)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:518\u001B[0m, in \u001B[0;36m_GradientsHelper\u001B[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001B[0m\n\u001B[0;32m    516\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Implementation of gradients().\"\"\"\u001B[39;00m\n\u001B[0;32m    517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 518\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf.gradients is not supported when eager execution \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    519\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis enabled. Use tf.GradientTape instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    520\u001B[0m ys \u001B[38;5;241m=\u001B[39m variable_utils\u001B[38;5;241m.\u001B[39mconvert_variables_to_tensors(_AsList(ys))\n\u001B[0;32m    521\u001B[0m xs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    522\u001B[0m     x\u001B[38;5;241m.\u001B[39mhandle \u001B[38;5;28;01mif\u001B[39;00m resource_variable_ops\u001B[38;5;241m.\u001B[39mis_resource_variable(x) \u001B[38;5;28;01melse\u001B[39;00m x\n\u001B[0;32m    523\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m _AsList(xs)\n\u001B[0;32m    524\u001B[0m ]\n",
      "\u001B[1;31mRuntimeError\u001B[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."
     ]
    }
   ],
   "source": [
    "# # Code in file autograd/tf_two_layer_net.py\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# \n",
    "# # First we set up the computational graph:\n",
    "# \n",
    "# # N is batch size; D_in is input dimension;\n",
    "# # H is hidden dimension; D_out is output dimension.\n",
    "# N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "# \n",
    "# # Create placeholders for the input and target data; these will be filled\n",
    "# # with real data when we execute the graph.\n",
    "# x = tf.keras.Input(dtype = tf.float32, shape=(None, D_in))\n",
    "# y = tf.keras.Input(dtype = tf.float32, shape=(None, D_out))\n",
    "# \n",
    "# # Create Variables for the weights and initialize them with random data.\n",
    "# # A TensorFlow Variable persists its value across executions of the graph.\n",
    "# w1 = tf.Variable(tf.random.normal((D_in, H)))\n",
    "# w2 = tf.Variable(tf.random.normal((H, D_out)))\n",
    "# \n",
    "# # Forward pass: Compute the predicted y using operations on TensorFlow Tensors.\n",
    "# # Note that this code does not actually perform any numeric operations; it\n",
    "# # merely sets up the computational graph that we will later execute.\n",
    "# h = tf.matmul(x, w1)\n",
    "# h_relu = tf.maximum(h, tf.zeros(1))\n",
    "# y_pred = tf.matmul(h_relu, w2)\n",
    "# \n",
    "# # Compute loss using operations on TensorFlow Tensors\n",
    "# loss = tf.reduce_sum((y - y_pred) ** 2.0)\n",
    "# \n",
    "# # Compute gradient of the loss with respect to w1 and w2.\n",
    "# grad_w1, grad_w2 = tf.gradients(loss, [w1, w2])\n",
    "# \n",
    "# # Update the weights using gradient descent. To actually update the weights\n",
    "# # we need to evaluate new_w1 and new_w2 when executing the graph. Note that\n",
    "# # in TensorFlow the the act of updating the value of the weights is part of\n",
    "# # the computational graph; in PyTorch this happens outside the computational\n",
    "# # graph.\n",
    "# learning_rate = 1e-6\n",
    "# new_w1 = w1.assign(w1 - learning_rate * grad_w1)\n",
    "# new_w2 = w2.assign(w2 - learning_rate * grad_w2)\n",
    "# \n",
    "# # Now we have built our computational graph, so we enter a TensorFlow session to\n",
    "# # actually execute the graph.\n",
    "# # Run the graph once to initialize the Variables w1 and w2.\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "# \n",
    "# x_value = np.random.randn(N, D_in)\n",
    "# y_value = np.random.randn(N, D_out)\n",
    "# \n",
    "# # Create numpy arrays holding the actual data for the inputs x and targets y\n",
    "# for _ in range(500):\n",
    "#     with tf.GradientTape() as tape:\n",
    "#       h= tf.matmul(x, w1)\n",
    "#       h_relu = tf.maximum(h, tf.zeros(1))\n",
    "#       y_pred = tf.matmul(h_relu, w2)\n",
    "#       loss = tf.reduce_sum((y - y_pred) ** 2.0)\n",
    "#     \n",
    "#     gradients = tape.gradient(loss, [w1, w2])\n",
    "#     optimizer.apply_gradients(zip(gradients, [w1, w2]))\n",
    "#     print(loss.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T03:20:11.065569100Z",
     "start_time": "2024-02-15T03:20:10.988979600Z"
    }
   },
   "id": "4d1e8e879c4c9889",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 693.6939086914062\n",
      "1 683.6755981445312\n",
      "2 674.2957763671875\n",
      "3 665.5421142578125\n",
      "4 657.3455200195312\n",
      "5 649.4089965820312\n",
      "6 641.779541015625\n",
      "7 634.5535888671875\n",
      "8 627.5890502929688\n",
      "9 620.905517578125\n",
      "10 614.453369140625\n",
      "11 608.1475219726562\n",
      "12 601.9097290039062\n",
      "13 595.731689453125\n",
      "14 589.6025390625\n",
      "15 583.4493408203125\n",
      "16 577.2836303710938\n",
      "17 571.1387939453125\n",
      "18 565.0403442382812\n",
      "19 558.940185546875\n",
      "20 552.7813720703125\n",
      "21 546.600341796875\n",
      "22 540.3707275390625\n",
      "23 534.0579223632812\n",
      "24 527.7005615234375\n",
      "25 521.2633056640625\n",
      "26 514.8046264648438\n",
      "27 508.23272705078125\n",
      "28 501.5549011230469\n",
      "29 494.79278564453125\n",
      "30 487.9367980957031\n",
      "31 480.9544982910156\n",
      "32 473.8597412109375\n",
      "33 466.6923522949219\n",
      "34 459.3495178222656\n",
      "35 451.9526672363281\n",
      "36 444.42620849609375\n",
      "37 436.7837829589844\n",
      "38 429.0760498046875\n",
      "39 421.26031494140625\n",
      "40 413.396484375\n",
      "41 405.40777587890625\n",
      "42 397.36578369140625\n",
      "43 389.2261962890625\n",
      "44 381.0356140136719\n",
      "45 372.7848205566406\n",
      "46 364.4912414550781\n",
      "47 356.1532287597656\n",
      "48 347.8157958984375\n",
      "49 339.4263916015625\n",
      "50 331.043212890625\n",
      "51 322.6508483886719\n",
      "52 314.326416015625\n",
      "53 306.0369873046875\n",
      "54 297.78533935546875\n",
      "55 289.60955810546875\n",
      "56 281.4678649902344\n",
      "57 273.4111328125\n",
      "58 265.42913818359375\n",
      "59 257.51287841796875\n",
      "60 249.7008056640625\n",
      "61 241.98773193359375\n",
      "62 234.4047088623047\n",
      "63 226.93885803222656\n",
      "64 219.5968017578125\n",
      "65 212.41127014160156\n",
      "66 205.369384765625\n",
      "67 198.507080078125\n",
      "68 191.81570434570312\n",
      "69 185.31700134277344\n",
      "70 178.99935913085938\n",
      "71 172.85867309570312\n",
      "72 166.90606689453125\n",
      "73 161.1144256591797\n",
      "74 155.4820556640625\n",
      "75 149.98080444335938\n",
      "76 144.67222595214844\n",
      "77 139.52743530273438\n",
      "78 134.53704833984375\n",
      "79 129.72396850585938\n",
      "80 125.08235931396484\n",
      "81 120.58094787597656\n",
      "82 116.23724365234375\n",
      "83 112.0379409790039\n",
      "84 107.98291015625\n",
      "85 104.07882690429688\n",
      "86 100.29667663574219\n",
      "87 96.64042663574219\n",
      "88 93.1131591796875\n",
      "89 89.69454956054688\n",
      "90 86.41194152832031\n",
      "91 83.2509765625\n",
      "92 80.20358276367188\n",
      "93 77.2742691040039\n",
      "94 74.44178009033203\n",
      "95 71.73332214355469\n",
      "96 69.11918640136719\n",
      "97 66.60786437988281\n",
      "98 64.17796325683594\n",
      "99 61.84456253051758\n",
      "100 59.5953369140625\n",
      "101 57.435699462890625\n",
      "102 55.35021209716797\n",
      "103 53.3443603515625\n",
      "104 51.42485809326172\n",
      "105 49.566184997558594\n",
      "106 47.78946304321289\n",
      "107 46.07843780517578\n",
      "108 44.42954635620117\n",
      "109 42.845359802246094\n",
      "110 41.323307037353516\n",
      "111 39.855072021484375\n",
      "112 38.44254684448242\n",
      "113 37.076690673828125\n",
      "114 35.770572662353516\n",
      "115 34.50811004638672\n",
      "116 33.28726577758789\n",
      "117 32.11566162109375\n",
      "118 30.98183822631836\n",
      "119 29.893497467041016\n",
      "120 28.84250259399414\n",
      "121 27.835948944091797\n",
      "122 26.865880966186523\n",
      "123 25.93745994567871\n",
      "124 25.041725158691406\n",
      "125 24.177059173583984\n",
      "126 23.344406127929688\n",
      "127 22.545753479003906\n",
      "128 21.775379180908203\n",
      "129 21.035903930664062\n",
      "130 20.32162094116211\n",
      "131 19.63043785095215\n",
      "132 18.96551513671875\n",
      "133 18.32394027709961\n",
      "134 17.70596694946289\n",
      "135 17.114208221435547\n",
      "136 16.540447235107422\n",
      "137 15.991523742675781\n",
      "138 15.46343994140625\n",
      "139 14.95421028137207\n",
      "140 14.4649658203125\n",
      "141 13.993200302124023\n",
      "142 13.538227081298828\n",
      "143 13.099933624267578\n",
      "144 12.676399230957031\n",
      "145 12.269186019897461\n",
      "146 11.876985549926758\n",
      "147 11.498640060424805\n",
      "148 11.133171081542969\n",
      "149 10.78115463256836\n",
      "150 10.441590309143066\n",
      "151 10.114678382873535\n",
      "152 9.79852294921875\n",
      "153 9.492835998535156\n",
      "154 9.197698593139648\n",
      "155 8.91305160522461\n",
      "156 8.637929916381836\n",
      "157 8.372098922729492\n",
      "158 8.115814208984375\n",
      "159 7.86726713180542\n",
      "160 7.6273956298828125\n",
      "161 7.395194053649902\n",
      "162 7.17072868347168\n",
      "163 6.953333854675293\n",
      "164 6.742586135864258\n",
      "165 6.539106369018555\n",
      "166 6.342106819152832\n",
      "167 6.150608539581299\n",
      "168 5.966416358947754\n",
      "169 5.78658390045166\n",
      "170 5.61342716217041\n",
      "171 5.446254730224609\n",
      "172 5.283844947814941\n",
      "173 5.126922130584717\n",
      "174 4.97503662109375\n",
      "175 4.828094482421875\n",
      "176 4.685950756072998\n",
      "177 4.54833459854126\n",
      "178 4.414897918701172\n",
      "179 4.285098552703857\n",
      "180 4.159881591796875\n",
      "181 4.038570880889893\n",
      "182 3.9205570220947266\n",
      "183 3.8064119815826416\n",
      "184 3.6952199935913086\n",
      "185 3.586982011795044\n",
      "186 3.482165575027466\n",
      "187 3.381030559539795\n",
      "188 3.282325267791748\n",
      "189 3.18710994720459\n",
      "190 3.0947799682617188\n",
      "191 3.0051000118255615\n",
      "192 2.918471574783325\n",
      "193 2.834324836730957\n",
      "194 2.7526047229766846\n",
      "195 2.673844814300537\n",
      "196 2.596895217895508\n",
      "197 2.522575616836548\n",
      "198 2.4507288932800293\n",
      "199 2.3808693885803223\n",
      "200 2.3131051063537598\n",
      "201 2.247147560119629\n",
      "202 2.1836507320404053\n",
      "203 2.121626377105713\n",
      "204 2.0617716312408447\n",
      "205 2.0034005641937256\n",
      "206 1.9471697807312012\n",
      "207 1.8923170566558838\n",
      "208 1.8393229246139526\n",
      "209 1.7874253988265991\n",
      "210 1.735266923904419\n",
      "211 1.6848609447479248\n",
      "212 1.635932445526123\n",
      "213 1.5884721279144287\n",
      "214 1.5424742698669434\n",
      "215 1.4979188442230225\n",
      "216 1.4548325538635254\n",
      "217 1.4131096601486206\n",
      "218 1.3726180791854858\n",
      "219 1.3333675861358643\n",
      "220 1.2952826023101807\n",
      "221 1.2581753730773926\n",
      "222 1.2223238945007324\n",
      "223 1.1873940229415894\n",
      "224 1.153664469718933\n",
      "225 1.1208676099777222\n",
      "226 1.0889365673065186\n",
      "227 1.0579650402069092\n",
      "228 1.0279181003570557\n",
      "229 0.99857497215271\n",
      "230 0.9700449705123901\n",
      "231 0.9423884153366089\n",
      "232 0.9155634045600891\n",
      "233 0.8896214365959167\n",
      "234 0.8643448948860168\n",
      "235 0.8399547338485718\n",
      "236 0.8163056373596191\n",
      "237 0.793192982673645\n",
      "238 0.7708080410957336\n",
      "239 0.7490735054016113\n",
      "240 0.7278681397438049\n",
      "241 0.7073068618774414\n",
      "242 0.6873583197593689\n",
      "243 0.6680314540863037\n",
      "244 0.6492823362350464\n",
      "245 0.6310324668884277\n",
      "246 0.6133496761322021\n",
      "247 0.5961800217628479\n",
      "248 0.5795624256134033\n",
      "249 0.5633691549301147\n",
      "250 0.5476768612861633\n",
      "251 0.532539427280426\n",
      "252 0.5176799893379211\n",
      "253 0.5033555626869202\n",
      "254 0.48944616317749023\n",
      "255 0.47592103481292725\n",
      "256 0.4627663493156433\n",
      "257 0.45006969571113586\n",
      "258 0.43764686584472656\n",
      "259 0.42563849687576294\n",
      "260 0.41395068168640137\n",
      "261 0.40263086557388306\n",
      "262 0.39159369468688965\n",
      "263 0.3809240162372589\n",
      "264 0.3705177307128906\n",
      "265 0.36043721437454224\n",
      "266 0.3506385087966919\n",
      "267 0.341116726398468\n",
      "268 0.33188700675964355\n",
      "269 0.3229483664035797\n",
      "270 0.3142038881778717\n",
      "271 0.3057703673839569\n",
      "272 0.29755303263664246\n",
      "273 0.28957241773605347\n",
      "274 0.28179970383644104\n",
      "275 0.2742951512336731\n",
      "276 0.2669414281845093\n",
      "277 0.25984323024749756\n",
      "278 0.2529051601886749\n",
      "279 0.24619117379188538\n",
      "280 0.2396475076675415\n",
      "281 0.2332826405763626\n",
      "282 0.22710536420345306\n",
      "283 0.22110214829444885\n",
      "284 0.21524059772491455\n",
      "285 0.20956294238567352\n",
      "286 0.20403796434402466\n",
      "287 0.1986689269542694\n",
      "288 0.19345006346702576\n",
      "289 0.1883755624294281\n",
      "290 0.18342198431491852\n",
      "291 0.17863616347312927\n",
      "292 0.17395564913749695\n",
      "293 0.16940557956695557\n",
      "294 0.1649770587682724\n",
      "295 0.1606687307357788\n",
      "296 0.15647247433662415\n",
      "297 0.15238916873931885\n",
      "298 0.14841903746128082\n",
      "299 0.14457042515277863\n",
      "300 0.14082089066505432\n",
      "301 0.13716760277748108\n",
      "302 0.13361963629722595\n",
      "303 0.13016164302825928\n",
      "304 0.1268143355846405\n",
      "305 0.12354280054569244\n",
      "306 0.12036804109811783\n",
      "307 0.11727388203144073\n",
      "308 0.11426513642072678\n",
      "309 0.11134444177150726\n",
      "310 0.1084909737110138\n",
      "311 0.1057279035449028\n",
      "312 0.10302270948886871\n",
      "313 0.10040416568517685\n",
      "314 0.09784339368343353\n",
      "315 0.09535618126392365\n",
      "316 0.09294140338897705\n",
      "317 0.09058873355388641\n",
      "318 0.08829809725284576\n",
      "319 0.08607026189565659\n",
      "320 0.08389940857887268\n",
      "321 0.08178143203258514\n",
      "322 0.07972455024719238\n",
      "323 0.07772261649370193\n",
      "324 0.07577408105134964\n",
      "325 0.07387949526309967\n",
      "326 0.07202331721782684\n",
      "327 0.07022030651569366\n",
      "328 0.06847326457500458\n",
      "329 0.06675726175308228\n",
      "330 0.0650852769613266\n",
      "331 0.0634569600224495\n",
      "332 0.06187046319246292\n",
      "333 0.060328319668769836\n",
      "334 0.058828700333833694\n",
      "335 0.0573592409491539\n",
      "336 0.05594039708375931\n",
      "337 0.054557811468839645\n",
      "338 0.05320073291659355\n",
      "339 0.05188978463411331\n",
      "340 0.050606876611709595\n",
      "341 0.049358103424310684\n",
      "342 0.048141784965991974\n",
      "343 0.046961769461631775\n",
      "344 0.04580884426832199\n",
      "345 0.04468705505132675\n",
      "346 0.04359523952007294\n",
      "347 0.04253008961677551\n",
      "348 0.04149198532104492\n",
      "349 0.04048062115907669\n",
      "350 0.03949882090091705\n",
      "351 0.03853823244571686\n",
      "352 0.03760375455021858\n",
      "353 0.03669290989637375\n",
      "354 0.035807520151138306\n",
      "355 0.034942928701639175\n",
      "356 0.03409877419471741\n",
      "357 0.03328144550323486\n",
      "358 0.032478611916303635\n",
      "359 0.031698331236839294\n",
      "360 0.03093743696808815\n",
      "361 0.03019660897552967\n",
      "362 0.029474927112460136\n",
      "363 0.028768954798579216\n",
      "364 0.028083819895982742\n",
      "365 0.0274127759039402\n",
      "366 0.02675800584256649\n",
      "367 0.026121046394109726\n",
      "368 0.02549923211336136\n",
      "369 0.024893971160054207\n",
      "370 0.02430140972137451\n",
      "371 0.023729369044303894\n",
      "372 0.02316342107951641\n",
      "373 0.022616514936089516\n",
      "374 0.022084340453147888\n",
      "375 0.021560635417699814\n",
      "376 0.021053986623883247\n",
      "377 0.020555272698402405\n",
      "378 0.02007623016834259\n",
      "379 0.019600970670580864\n",
      "380 0.01914191246032715\n",
      "381 0.01869349740445614\n",
      "382 0.018254002556204796\n",
      "383 0.017825182527303696\n",
      "384 0.01740456372499466\n",
      "385 0.016996635124087334\n",
      "386 0.016596630215644836\n",
      "387 0.01620648428797722\n",
      "388 0.01582707278430462\n",
      "389 0.015455487184226513\n",
      "390 0.015094541013240814\n",
      "391 0.01474218349903822\n",
      "392 0.014397794380784035\n",
      "393 0.014061425812542439\n",
      "394 0.013733984902501106\n",
      "395 0.013414116576313972\n",
      "396 0.013103104196488857\n",
      "397 0.012797243893146515\n",
      "398 0.012501353397965431\n",
      "399 0.012210845947265625\n",
      "400 0.011928172782063484\n",
      "401 0.011651994660496712\n",
      "402 0.01138258259743452\n",
      "403 0.011119822971522808\n",
      "404 0.01086238119751215\n",
      "405 0.010611874982714653\n",
      "406 0.010366491042077541\n",
      "407 0.010127034969627857\n",
      "408 0.00989455170929432\n",
      "409 0.009666805155575275\n",
      "410 0.009445209056138992\n",
      "411 0.009227780625224113\n",
      "412 0.009016239084303379\n",
      "413 0.008809003978967667\n",
      "414 0.00860766414552927\n",
      "415 0.008409365080296993\n",
      "416 0.008218333125114441\n",
      "417 0.008030888624489307\n",
      "418 0.007846556603908539\n",
      "419 0.007667415775358677\n",
      "420 0.007493205834180117\n",
      "421 0.0073227849788963795\n",
      "422 0.0071566468104720116\n",
      "423 0.0069947391748428345\n",
      "424 0.00683561060577631\n",
      "425 0.006681499071419239\n",
      "426 0.006529883481562138\n",
      "427 0.006381814833730459\n",
      "428 0.006238687317818403\n",
      "429 0.006097576580941677\n",
      "430 0.005960559006780386\n",
      "431 0.005825703032314777\n",
      "432 0.005695067346096039\n",
      "433 0.005566448904573917\n",
      "434 0.005441593937575817\n",
      "435 0.005319749005138874\n",
      "436 0.005200725514441729\n",
      "437 0.00508427619934082\n",
      "438 0.004970005713403225\n",
      "439 0.004858996719121933\n",
      "440 0.004750877618789673\n",
      "441 0.00464430870488286\n",
      "442 0.004541317000985146\n",
      "443 0.004439747426658869\n",
      "444 0.004341054242104292\n",
      "445 0.004244660492986441\n",
      "446 0.004149928689002991\n",
      "447 0.00405768770724535\n",
      "448 0.003968503791838884\n",
      "449 0.0038798681925982237\n",
      "450 0.003794030984863639\n",
      "451 0.003710060380399227\n",
      "452 0.0036278991028666496\n",
      "453 0.0035478943027555943\n",
      "454 0.00346961198374629\n",
      "455 0.003393029561266303\n",
      "456 0.0033183619379997253\n",
      "457 0.0032451811712235212\n",
      "458 0.0031739315018057823\n",
      "459 0.0031037647277116776\n",
      "460 0.0030359027441591024\n",
      "461 0.0029694288969039917\n",
      "462 0.0029041683301329613\n",
      "463 0.002840606728568673\n",
      "464 0.0027782113756984472\n",
      "465 0.0027175932191312313\n",
      "466 0.0026582630816847086\n",
      "467 0.002600188599899411\n",
      "468 0.0025434803683310747\n",
      "469 0.0024879754055291414\n",
      "470 0.0024339756928384304\n",
      "471 0.0023806700482964516\n",
      "472 0.0023289541713893414\n",
      "473 0.0022784387692809105\n",
      "474 0.0022290004417300224\n",
      "475 0.0021805271971970797\n",
      "476 0.0021332469768822193\n",
      "477 0.0020870771259069443\n",
      "478 0.0020418157801032066\n",
      "479 0.0019975099712610245\n",
      "480 0.0019545089453458786\n",
      "481 0.0019123367965221405\n",
      "482 0.0018708453280851245\n",
      "483 0.0018306297715753317\n",
      "484 0.0017910714959725738\n",
      "485 0.0017525011207908392\n",
      "486 0.001714965794235468\n",
      "487 0.0016779194120317698\n",
      "488 0.0016419459134340286\n",
      "489 0.0016066732350736856\n",
      "490 0.0015720765804871917\n",
      "491 0.0015382744604721665\n",
      "492 0.0015054026152938604\n",
      "493 0.0014732962008565664\n",
      "494 0.0014415920013561845\n",
      "495 0.0014108801260590553\n",
      "496 0.0013806178467348218\n",
      "497 0.0013511041179299355\n",
      "498 0.001322357915341854\n",
      "499 0.0012941689928993583\n"
     ]
    }
   ],
   "source": [
    "# Code in file nn/two_layer_net_nn.py\n",
    "import torch\n",
    "\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda') # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. Each Linear Module computes output from input using a\n",
    "# linear function, and holds internal Tensors for its weight and bias.\n",
    "# After constructing the model we use the .to() method to move it to the\n",
    "# desired device.\n",
    "model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(D_in, H),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(H, H),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(H, D_out),\n",
    "        ).to(device)\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function. Setting\n",
    "# reduction='sum' means that we are computing the *sum* of squared errors rather\n",
    "# than the mean; this is for consistency with the examples above where we\n",
    "# manually compute the loss, but in practice it is more common to use mean\n",
    "# squared error as a loss by setting reduction='elementwise_mean'.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-4\n",
    "for t in range(500):\n",
    "  # Forward pass: compute predicted y by passing x to the model. Module objects\n",
    "  # override the __call__ operator so you can call them like functions. When\n",
    "  # doing so you pass a Tensor of input data to the Module and it produces\n",
    "  # a Tensor of output data.\n",
    "  y_pred = model(x)\n",
    "\n",
    "  # Compute and print loss. We pass Tensors containing the predicted and true\n",
    "  # values of y, and the loss function returns a Tensor containing the loss.\n",
    "  loss = loss_fn(y_pred, y)\n",
    "  print(t, loss.item())\n",
    "  \n",
    "  # Zero the gradients before running the backward pass.\n",
    "  model.zero_grad()\n",
    "\n",
    "  # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "  # parameters of the model. Internally, the parameters of each Module are stored\n",
    "  # in Tensors with requires_grad=True, so this call will compute gradients for\n",
    "  # all learnable parameters in the model.\n",
    "  loss.backward()\n",
    "\n",
    "  # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
    "  # we can access its data and gradients like we did before.\n",
    "  with torch.no_grad():\n",
    "    for param in model.parameters():\n",
    "      param.data -= learning_rate * param.grad"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T03:30:34.153726100Z",
     "start_time": "2024-02-15T03:30:33.417601100Z"
    }
   },
   "id": "79cb3c52072c3c8b",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 612.4791259765625\n",
      "1 605.2576293945312\n",
      "2 598.3970947265625\n",
      "3 591.7305297851562\n",
      "4 585.2027587890625\n",
      "5 578.8516845703125\n",
      "6 572.7098999023438\n",
      "7 566.7997436523438\n",
      "8 561.0980224609375\n",
      "9 555.5546875\n",
      "10 550.2174682617188\n",
      "11 544.9686889648438\n",
      "12 539.8546142578125\n",
      "13 534.8262939453125\n",
      "14 529.9065551757812\n",
      "15 525.0681762695312\n",
      "16 520.29443359375\n",
      "17 515.600830078125\n",
      "18 510.95013427734375\n",
      "19 506.3228454589844\n",
      "20 501.7575988769531\n",
      "21 497.225830078125\n",
      "22 492.7273864746094\n",
      "23 488.2712097167969\n",
      "24 483.81451416015625\n",
      "25 479.34039306640625\n",
      "26 474.8628234863281\n",
      "27 470.3786315917969\n",
      "28 465.8890380859375\n",
      "29 461.4114685058594\n",
      "30 456.94708251953125\n",
      "31 452.45941162109375\n",
      "32 447.9401550292969\n",
      "33 443.4000244140625\n",
      "34 438.8351135253906\n",
      "35 434.2449035644531\n",
      "36 429.669189453125\n",
      "37 425.08294677734375\n",
      "38 420.47161865234375\n",
      "39 415.84014892578125\n",
      "40 411.2151184082031\n",
      "41 406.58160400390625\n",
      "42 401.9275207519531\n",
      "43 397.2799072265625\n",
      "44 392.625\n",
      "45 387.95062255859375\n",
      "46 383.26025390625\n",
      "47 378.567626953125\n",
      "48 373.86456298828125\n",
      "49 369.1519775390625\n",
      "50 364.44024658203125\n",
      "51 359.7436218261719\n",
      "52 355.04132080078125\n",
      "53 350.3331604003906\n",
      "54 345.6390075683594\n",
      "55 340.9569091796875\n",
      "56 336.2799072265625\n",
      "57 331.61212158203125\n",
      "58 326.9421081542969\n",
      "59 322.28216552734375\n",
      "60 317.61944580078125\n",
      "61 312.974853515625\n",
      "62 308.35809326171875\n",
      "63 303.7574768066406\n",
      "64 299.1756286621094\n",
      "65 294.60198974609375\n",
      "66 290.0499267578125\n",
      "67 285.5181884765625\n",
      "68 281.0163269042969\n",
      "69 276.54449462890625\n",
      "70 272.10125732421875\n",
      "71 267.667724609375\n",
      "72 263.25390625\n",
      "73 258.8611145019531\n",
      "74 254.48541259765625\n",
      "75 250.12046813964844\n",
      "76 245.7753143310547\n",
      "77 241.44546508789062\n",
      "78 237.13986206054688\n",
      "79 232.85162353515625\n",
      "80 228.5806121826172\n",
      "81 224.33303833007812\n",
      "82 220.10324096679688\n",
      "83 215.90113830566406\n",
      "84 211.73487854003906\n",
      "85 207.58848571777344\n",
      "86 203.48187255859375\n",
      "87 199.41183471679688\n",
      "88 195.36373901367188\n",
      "89 191.35670471191406\n",
      "90 187.38111877441406\n",
      "91 183.44766235351562\n",
      "92 179.54586791992188\n",
      "93 175.68240356445312\n",
      "94 171.85394287109375\n",
      "95 168.06356811523438\n",
      "96 164.3201141357422\n",
      "97 160.622802734375\n",
      "98 156.9632568359375\n",
      "99 153.3446044921875\n",
      "100 149.77767944335938\n",
      "101 146.2486572265625\n",
      "102 142.7600555419922\n",
      "103 139.32162475585938\n",
      "104 135.92913818359375\n",
      "105 132.5817108154297\n",
      "106 129.27500915527344\n",
      "107 126.01151275634766\n",
      "108 122.79035949707031\n",
      "109 119.62165069580078\n",
      "110 116.505615234375\n",
      "111 113.43799591064453\n",
      "112 110.41596221923828\n",
      "113 107.43815612792969\n",
      "114 104.50594329833984\n",
      "115 101.61756134033203\n",
      "116 98.7801284790039\n",
      "117 95.98291015625\n",
      "118 93.23936462402344\n",
      "119 90.55157470703125\n",
      "120 87.91059112548828\n",
      "121 85.3170166015625\n",
      "122 82.77880859375\n",
      "123 80.29541015625\n",
      "124 77.86613464355469\n",
      "125 75.4950942993164\n",
      "126 73.17308044433594\n",
      "127 70.89698791503906\n",
      "128 68.6744613647461\n",
      "129 66.50434112548828\n",
      "130 64.37893676757812\n",
      "131 62.30059814453125\n",
      "132 60.272918701171875\n",
      "133 58.28992462158203\n",
      "134 56.35334777832031\n",
      "135 54.46352767944336\n",
      "136 52.61982345581055\n",
      "137 50.820953369140625\n",
      "138 49.06740951538086\n",
      "139 47.35708236694336\n",
      "140 45.695865631103516\n",
      "141 44.08443069458008\n",
      "142 42.517601013183594\n",
      "143 40.997989654541016\n",
      "144 39.519142150878906\n",
      "145 38.0815315246582\n",
      "146 36.6860237121582\n",
      "147 35.33696746826172\n",
      "148 34.030006408691406\n",
      "149 32.76587677001953\n",
      "150 31.538639068603516\n",
      "151 30.346141815185547\n",
      "152 29.193431854248047\n",
      "153 28.080095291137695\n",
      "154 27.000747680664062\n",
      "155 25.956756591796875\n",
      "156 24.948307037353516\n",
      "157 23.97212028503418\n",
      "158 23.029735565185547\n",
      "159 22.120201110839844\n",
      "160 21.24085235595703\n",
      "161 20.39175033569336\n",
      "162 19.57301139831543\n",
      "163 18.782878875732422\n",
      "164 18.021282196044922\n",
      "165 17.286298751831055\n",
      "166 16.578983306884766\n",
      "167 15.895650863647461\n",
      "168 15.236790657043457\n",
      "169 14.601578712463379\n",
      "170 13.989506721496582\n",
      "171 13.399076461791992\n",
      "172 12.830522537231445\n",
      "173 12.283571243286133\n",
      "174 11.756698608398438\n",
      "175 11.248716354370117\n",
      "176 10.759543418884277\n",
      "177 10.289167404174805\n",
      "178 9.836662292480469\n",
      "179 9.402917861938477\n",
      "180 8.986583709716797\n",
      "181 8.586999893188477\n",
      "182 8.203591346740723\n",
      "183 7.836101055145264\n",
      "184 7.48304557800293\n",
      "185 7.145172595977783\n",
      "186 6.821592807769775\n",
      "187 6.511342525482178\n",
      "188 6.214338302612305\n",
      "189 5.929450988769531\n",
      "190 5.656732559204102\n",
      "191 5.396036624908447\n",
      "192 5.146025657653809\n",
      "193 4.906368732452393\n",
      "194 4.6765618324279785\n",
      "195 4.456656455993652\n",
      "196 4.2458319664001465\n",
      "197 4.044342041015625\n",
      "198 3.8515076637268066\n",
      "199 3.666804790496826\n",
      "200 3.4903836250305176\n",
      "201 3.3217668533325195\n",
      "202 3.1608059406280518\n",
      "203 3.007009506225586\n",
      "204 2.8604848384857178\n",
      "205 2.72055721282959\n",
      "206 2.587332248687744\n",
      "207 2.460277557373047\n",
      "208 2.33897066116333\n",
      "209 2.224421977996826\n",
      "210 2.1150028705596924\n",
      "211 2.0107975006103516\n",
      "212 1.9113519191741943\n",
      "213 1.8164069652557373\n",
      "214 1.7259297370910645\n",
      "215 1.6395740509033203\n",
      "216 1.5574607849121094\n",
      "217 1.4793553352355957\n",
      "218 1.4048384428024292\n",
      "219 1.3338351249694824\n",
      "220 1.2662630081176758\n",
      "221 1.2019232511520386\n",
      "222 1.140642523765564\n",
      "223 1.082391381263733\n",
      "224 1.0270073413848877\n",
      "225 0.9742686748504639\n",
      "226 0.9241459369659424\n",
      "227 0.8764666318893433\n",
      "228 0.8311889171600342\n",
      "229 0.7881802320480347\n",
      "230 0.7473247051239014\n",
      "231 0.708693265914917\n",
      "232 0.672033965587616\n",
      "233 0.6373152732849121\n",
      "234 0.60439133644104\n",
      "235 0.5732256770133972\n",
      "236 0.5436832904815674\n",
      "237 0.5156391859054565\n",
      "238 0.489008367061615\n",
      "239 0.4637259244918823\n",
      "240 0.4397529363632202\n",
      "241 0.41702699661254883\n",
      "242 0.3954356908798218\n",
      "243 0.3749607801437378\n",
      "244 0.35550251603126526\n",
      "245 0.33705878257751465\n",
      "246 0.31963300704956055\n",
      "247 0.30308887362480164\n",
      "248 0.28737562894821167\n",
      "249 0.27251148223876953\n",
      "250 0.2583947777748108\n",
      "251 0.2450285702943802\n",
      "252 0.23235946893692017\n",
      "253 0.22036108374595642\n",
      "254 0.2089935839176178\n",
      "255 0.19820718467235565\n",
      "256 0.18796560168266296\n",
      "257 0.17825013399124146\n",
      "258 0.1690603643655777\n",
      "259 0.16035951673984528\n",
      "260 0.1520960032939911\n",
      "261 0.14427965879440308\n",
      "262 0.1368536353111267\n",
      "263 0.12981370091438293\n",
      "264 0.12314249575138092\n",
      "265 0.11682295799255371\n",
      "266 0.11083479970693588\n",
      "267 0.10515964031219482\n",
      "268 0.09976252913475037\n",
      "269 0.09463932365179062\n",
      "270 0.0897810086607933\n",
      "271 0.08518104255199432\n",
      "272 0.08081639558076859\n",
      "273 0.07668358087539673\n",
      "274 0.07276035845279694\n",
      "275 0.0690404623746872\n",
      "276 0.06551890820264816\n",
      "277 0.06218152865767479\n",
      "278 0.05901756510138512\n",
      "279 0.05602164566516876\n",
      "280 0.05317606404423714\n",
      "281 0.050478365272283554\n",
      "282 0.04791683703660965\n",
      "283 0.04549082741141319\n",
      "284 0.04319281876087189\n",
      "285 0.04101371765136719\n",
      "286 0.03894127905368805\n",
      "287 0.036976974457502365\n",
      "288 0.03511844575405121\n",
      "289 0.033351317048072815\n",
      "290 0.03167647123336792\n",
      "291 0.030086886137723923\n",
      "292 0.02857872098684311\n",
      "293 0.027147630229592323\n",
      "294 0.025792500004172325\n",
      "295 0.02450636774301529\n",
      "296 0.023286424577236176\n",
      "297 0.022132834419608116\n",
      "298 0.021034151315689087\n",
      "299 0.01999674364924431\n",
      "300 0.01901295781135559\n",
      "301 0.018078552559018135\n",
      "302 0.017191674560308456\n",
      "303 0.01634940877556801\n",
      "304 0.015550227835774422\n",
      "305 0.01479126513004303\n",
      "306 0.014069803059101105\n",
      "307 0.013384204357862473\n",
      "308 0.012733769603073597\n",
      "309 0.012117240577936172\n",
      "310 0.011530479416251183\n",
      "311 0.01097453385591507\n",
      "312 0.010447385720908642\n",
      "313 0.009945391677320004\n",
      "314 0.009469912387430668\n",
      "315 0.00901738926768303\n",
      "316 0.008586637675762177\n",
      "317 0.008177346549928188\n",
      "318 0.007788434624671936\n",
      "319 0.0074187880381941795\n",
      "320 0.007067392580211163\n",
      "321 0.006733507849276066\n",
      "322 0.006415316369384527\n",
      "323 0.006113497540354729\n",
      "324 0.005825947970151901\n",
      "325 0.005552425514906645\n",
      "326 0.005292688030749559\n",
      "327 0.005048912484198809\n",
      "328 0.00481731491163373\n",
      "329 0.00459679588675499\n",
      "330 0.004385720938444138\n",
      "331 0.004185066092759371\n",
      "332 0.0039937375113368034\n",
      "333 0.0038114842027425766\n",
      "334 0.0036378037184476852\n",
      "335 0.0034720352850854397\n",
      "336 0.0033145342022180557\n",
      "337 0.003164443885907531\n",
      "338 0.0030213017016649246\n",
      "339 0.0028846641071140766\n",
      "340 0.0027546698693186045\n",
      "341 0.002630924340337515\n",
      "342 0.002512930426746607\n",
      "343 0.0024006133899092674\n",
      "344 0.0022933355066925287\n",
      "345 0.002191167790442705\n",
      "346 0.0020936396904289722\n",
      "347 0.00200072699226439\n",
      "348 0.0019122869707643986\n",
      "349 0.0018278802745044231\n",
      "350 0.0017472089966759086\n",
      "351 0.0016702094580978155\n",
      "352 0.0015969309024512768\n",
      "353 0.0015270280418917537\n",
      "354 0.0014602894661948085\n",
      "355 0.0013966357801109552\n",
      "356 0.0013357079587876797\n",
      "357 0.001277643023058772\n",
      "358 0.0012222432997077703\n",
      "359 0.001169327413663268\n",
      "360 0.0011187345953658223\n",
      "361 0.0010704566957429051\n",
      "362 0.0010243498254567385\n",
      "363 0.000980351003818214\n",
      "364 0.0009382686112076044\n",
      "365 0.0008980645798146725\n",
      "366 0.0008596631232649088\n",
      "367 0.0008228890364989638\n",
      "368 0.000787764263805002\n",
      "369 0.0007543050451204181\n",
      "370 0.0007223016582429409\n",
      "371 0.0006916431593708694\n",
      "372 0.0006622676737606525\n",
      "373 0.0006342704291455448\n",
      "374 0.0006074734264984727\n",
      "375 0.0005818841746076941\n",
      "376 0.0005573523230850697\n",
      "377 0.0005339410854503512\n",
      "378 0.000511499005369842\n",
      "379 0.0004900568164885044\n",
      "380 0.00046956673031672835\n",
      "381 0.00044995261123403907\n",
      "382 0.00043116373126395047\n",
      "383 0.0004131230525672436\n",
      "384 0.0003959478926844895\n",
      "385 0.00037951889680698514\n",
      "386 0.0003637667396105826\n",
      "387 0.0003486811474431306\n",
      "388 0.00033425178844481707\n",
      "389 0.000320461142109707\n",
      "390 0.0003073011466767639\n",
      "391 0.0002946938911918551\n",
      "392 0.0002826097479555756\n",
      "393 0.00027100727311335504\n",
      "394 0.00025985189131461084\n",
      "395 0.00024918836425058544\n",
      "396 0.00023899310326669365\n",
      "397 0.00022920811898075044\n",
      "398 0.00021989228844176978\n",
      "399 0.0002109265187755227\n",
      "400 0.000202356866793707\n",
      "401 0.0001941172668011859\n",
      "402 0.00018624335643835366\n",
      "403 0.0001787312503438443\n",
      "404 0.000171518258866854\n",
      "405 0.0001645541051402688\n",
      "406 0.00015787607117090374\n",
      "407 0.00015148887177929282\n",
      "408 0.00014538160758093\n",
      "409 0.0001395203871652484\n",
      "410 0.00013389374362304807\n",
      "411 0.00012851883366238326\n",
      "412 0.00012335850624367595\n",
      "413 0.00011843109678011388\n",
      "414 0.00011367222759872675\n",
      "415 0.00010911208664765581\n",
      "416 0.00010473158909007907\n",
      "417 0.00010052888683276251\n",
      "418 9.652383596403524e-05\n",
      "419 9.266716369893402e-05\n",
      "420 8.89682414708659e-05\n",
      "421 8.541741408407688e-05\n",
      "422 8.200528100132942e-05\n",
      "423 7.874787843320519e-05\n",
      "424 7.560733502032235e-05\n",
      "425 7.261511200340465e-05\n",
      "426 6.97275172569789e-05\n",
      "427 6.696365744573995e-05\n",
      "428 6.430806388380006e-05\n",
      "429 6.175263115437701e-05\n",
      "430 5.931398118264042e-05\n",
      "431 5.696636435459368e-05\n",
      "432 5.4714222642360255e-05\n",
      "433 5.2548701205523685e-05\n",
      "434 5.0475795433158055e-05\n",
      "435 4.8475856601726264e-05\n",
      "436 4.656295641325414e-05\n",
      "437 4.4722040911437944e-05\n",
      "438 4.295812686905265e-05\n",
      "439 4.126956991967745e-05\n",
      "440 3.9646885852562264e-05\n",
      "441 3.807415851042606e-05\n",
      "442 3.6577173887053505e-05\n",
      "443 3.5138360544806346e-05\n",
      "444 3.375530650373548e-05\n",
      "445 3.242447564844042e-05\n",
      "446 3.114639548584819e-05\n",
      "447 2.992483859998174e-05\n",
      "448 2.8744887458742596e-05\n",
      "449 2.76143109658733e-05\n",
      "450 2.6534005883149803e-05\n",
      "451 2.549380405980628e-05\n",
      "452 2.4495180696249008e-05\n",
      "453 2.3531487386208028e-05\n",
      "454 2.2609616280533373e-05\n",
      "455 2.1718675270676613e-05\n",
      "456 2.0866667910013348e-05\n",
      "457 2.0045785277034156e-05\n",
      "458 1.9259437976870686e-05\n",
      "459 1.850194348662626e-05\n",
      "460 1.7774760635802522e-05\n",
      "461 1.7077614756999537e-05\n",
      "462 1.6406551367253996e-05\n",
      "463 1.5761235772515647e-05\n",
      "464 1.5142916709010024e-05\n",
      "465 1.4548186300089583e-05\n",
      "466 1.3978438801132143e-05\n",
      "467 1.34259262267733e-05\n",
      "468 1.2900146430183668e-05\n",
      "469 1.2397161299304571e-05\n",
      "470 1.1906959116458893e-05\n",
      "471 1.1436298336775508e-05\n",
      "472 1.0990902410412673e-05\n",
      "473 1.0555529115663376e-05\n",
      "474 1.0139599908143282e-05\n",
      "475 9.742153451952618e-06\n",
      "476 9.36001288209809e-06\n",
      "477 8.990785318019334e-06\n",
      "478 8.635941412649117e-06\n",
      "479 8.294503459183034e-06\n",
      "480 7.9688916230225e-06\n",
      "481 7.653126885998063e-06\n",
      "482 7.351152362389257e-06\n",
      "483 7.063910743454471e-06\n",
      "484 6.7844266595784575e-06\n",
      "485 6.515847871924052e-06\n",
      "486 6.2577951212006155e-06\n",
      "487 6.00789417148917e-06\n",
      "488 5.773058092017891e-06\n",
      "489 5.543696715903934e-06\n",
      "490 5.32500689587323e-06\n",
      "491 5.112833605380729e-06\n",
      "492 4.911594714940293e-06\n",
      "493 4.716249804914696e-06\n",
      "494 4.529423677013256e-06\n",
      "495 4.348849415691802e-06\n",
      "496 4.1764433262869716e-06\n",
      "497 4.010915290564299e-06\n",
      "498 3.851260771625675e-06\n",
      "499 3.6977553463657387e-06\n"
     ]
    }
   ],
   "source": [
    "# Code in file nn/two_layer_net_optim.py\n",
    "import torch\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs.\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# Use the nn package to define our model and loss function.\n",
    "model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(D_in, H),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(H, H),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(H, D_out),\n",
    "        )\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Use the optim package to define an Optimizer that will update the weights of\n",
    "# the model for us. Here we will use Adam; the optim package contains many other\n",
    "# optimization algorithms. The first argument to the Adam constructor tells the\n",
    "# optimizer which Tensors it should update.\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(500):\n",
    "  # Forward pass: compute predicted y by passing x to the model.\n",
    "  y_pred = model(x)\n",
    "\n",
    "  # Compute and print loss.\n",
    "  loss = loss_fn(y_pred, y)\n",
    "  print(t, loss.item())\n",
    "  \n",
    "  # Before the backward pass, use the optimizer object to zero all of the\n",
    "  # gradients for the Tensors it will update (which are the learnable weights\n",
    "  # of the model)\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "  loss.backward()\n",
    "\n",
    "  # Calling the step function on an Optimizer makes an update to its parameters\n",
    "  optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T03:32:47.116915500Z",
     "start_time": "2024-02-15T03:32:45.127550700Z"
    }
   },
   "id": "2ea809f92f3d6202",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 640.0499877929688\n",
      "1 592.2871704101562\n",
      "2 551.427734375\n",
      "3 515.4647827148438\n",
      "4 483.7063903808594\n",
      "5 455.10589599609375\n",
      "6 429.28814697265625\n",
      "7 405.7327575683594\n",
      "8 384.0366516113281\n",
      "9 363.7674255371094\n",
      "10 344.8120422363281\n",
      "11 327.03045654296875\n",
      "12 310.298583984375\n",
      "13 294.44781494140625\n",
      "14 279.47308349609375\n",
      "15 265.2679443359375\n",
      "16 251.7413330078125\n",
      "17 238.86087036132812\n",
      "18 226.6383819580078\n",
      "19 214.96165466308594\n",
      "20 203.7803955078125\n",
      "21 193.09146118164062\n",
      "22 182.90599060058594\n",
      "23 173.15521240234375\n",
      "24 163.8271942138672\n",
      "25 154.90084838867188\n",
      "26 146.3857879638672\n",
      "27 138.24411010742188\n",
      "28 130.5223846435547\n",
      "29 123.19560241699219\n",
      "30 116.22514343261719\n",
      "31 109.62008666992188\n",
      "32 103.36155700683594\n",
      "33 97.43389892578125\n",
      "34 91.8178939819336\n",
      "35 86.49102020263672\n",
      "36 81.4552001953125\n",
      "37 76.69800567626953\n",
      "38 72.2008056640625\n",
      "39 67.95809173583984\n",
      "40 63.94975280761719\n",
      "41 60.173179626464844\n",
      "42 56.61274719238281\n",
      "43 53.26205825805664\n",
      "44 50.10822677612305\n",
      "45 47.13569641113281\n",
      "46 44.34131622314453\n",
      "47 41.71448516845703\n",
      "48 39.242210388183594\n",
      "49 36.91322326660156\n",
      "50 34.725921630859375\n",
      "51 32.673255920410156\n",
      "52 30.741487503051758\n",
      "53 28.925277709960938\n",
      "54 27.21857261657715\n",
      "55 25.619281768798828\n",
      "56 24.116966247558594\n",
      "57 22.709657669067383\n",
      "58 21.388561248779297\n",
      "59 20.147735595703125\n",
      "60 18.982603073120117\n",
      "61 17.889434814453125\n",
      "62 16.862401962280273\n",
      "63 15.89834213256836\n",
      "64 14.990739822387695\n",
      "65 14.137869834899902\n",
      "66 13.336209297180176\n",
      "67 12.583014488220215\n",
      "68 11.877121925354004\n",
      "69 11.214312553405762\n",
      "70 10.590780258178711\n",
      "71 10.005175590515137\n",
      "72 9.454736709594727\n",
      "73 8.936548233032227\n",
      "74 8.447367668151855\n",
      "75 7.9874043464660645\n",
      "76 7.555166721343994\n",
      "77 7.1472392082214355\n",
      "78 6.763107776641846\n",
      "79 6.401783466339111\n",
      "80 6.061629295349121\n",
      "81 5.7412824630737305\n",
      "82 5.439306259155273\n",
      "83 5.155342102050781\n",
      "84 4.887496471405029\n",
      "85 4.634701728820801\n",
      "86 4.396103858947754\n",
      "87 4.170876502990723\n",
      "88 3.958045482635498\n",
      "89 3.7573559284210205\n",
      "90 3.5678436756134033\n",
      "91 3.389110803604126\n",
      "92 3.220029830932617\n",
      "93 3.060065269470215\n",
      "94 2.9087884426116943\n",
      "95 2.765578269958496\n",
      "96 2.629915475845337\n",
      "97 2.5016322135925293\n",
      "98 2.380397081375122\n",
      "99 2.265936851501465\n",
      "100 2.157414436340332\n",
      "101 2.054591655731201\n",
      "102 1.9571349620819092\n",
      "103 1.8647836446762085\n",
      "104 1.7773030996322632\n",
      "105 1.6942387819290161\n",
      "106 1.6154098510742188\n",
      "107 1.5405807495117188\n",
      "108 1.4695062637329102\n",
      "109 1.4020967483520508\n",
      "110 1.3381400108337402\n",
      "111 1.277482509613037\n",
      "112 1.2197771072387695\n",
      "113 1.1648774147033691\n",
      "114 1.1126705408096313\n",
      "115 1.0630393028259277\n",
      "116 1.0158418416976929\n",
      "117 0.970892608165741\n",
      "118 0.9281072020530701\n",
      "119 0.8873575925827026\n",
      "120 0.848609209060669\n",
      "121 0.8117421865463257\n",
      "122 0.7767468690872192\n",
      "123 0.7434221506118774\n",
      "124 0.711704671382904\n",
      "125 0.6814671754837036\n",
      "126 0.6526204347610474\n",
      "127 0.6251084208488464\n",
      "128 0.5989294052124023\n",
      "129 0.5739467740058899\n",
      "130 0.5501092672348022\n",
      "131 0.5273320078849792\n",
      "132 0.5055786967277527\n",
      "133 0.48478686809539795\n",
      "134 0.46496662497520447\n",
      "135 0.44601553678512573\n",
      "136 0.42790937423706055\n",
      "137 0.410593718290329\n",
      "138 0.3940378427505493\n",
      "139 0.3782133460044861\n",
      "140 0.363075852394104\n",
      "141 0.34860295057296753\n",
      "142 0.3347778618335724\n",
      "143 0.3215482234954834\n",
      "144 0.3088673949241638\n",
      "145 0.29673177003860474\n",
      "146 0.2851158082485199\n",
      "147 0.27398303151130676\n",
      "148 0.26331961154937744\n",
      "149 0.25311294198036194\n",
      "150 0.2433396875858307\n",
      "151 0.23396189510822296\n",
      "152 0.2249763160943985\n",
      "153 0.21635612845420837\n",
      "154 0.20809459686279297\n",
      "155 0.20017458498477936\n",
      "156 0.19257541000843048\n",
      "157 0.1852889358997345\n",
      "158 0.17829886078834534\n",
      "159 0.1715886890888214\n",
      "160 0.16514936089515686\n",
      "161 0.15896709263324738\n",
      "162 0.15303826332092285\n",
      "163 0.1473418027162552\n",
      "164 0.14187154173851013\n",
      "165 0.13661909103393555\n",
      "166 0.1315828561782837\n",
      "167 0.12673978507518768\n",
      "168 0.12208489328622818\n",
      "169 0.11761094629764557\n",
      "170 0.1133178099989891\n",
      "171 0.10919161885976791\n",
      "172 0.10522128641605377\n",
      "173 0.10140770673751831\n",
      "174 0.09773822128772736\n",
      "175 0.09421489387750626\n",
      "176 0.09082721918821335\n",
      "177 0.08756569772958755\n",
      "178 0.08443031460046768\n",
      "179 0.08141279220581055\n",
      "180 0.07850970327854156\n",
      "181 0.07571659237146378\n",
      "182 0.07305367290973663\n",
      "183 0.07049459218978882\n",
      "184 0.06803131103515625\n",
      "185 0.0656585767865181\n",
      "186 0.0633755773305893\n",
      "187 0.061177901923656464\n",
      "188 0.05906342342495918\n",
      "189 0.057027462869882584\n",
      "190 0.055066660046577454\n",
      "191 0.05317755788564682\n",
      "192 0.05135906860232353\n",
      "193 0.04960576072335243\n",
      "194 0.047918085008859634\n",
      "195 0.04629100114107132\n",
      "196 0.044721972197294235\n",
      "197 0.04321127012372017\n",
      "198 0.04175575450062752\n",
      "199 0.040352221578359604\n",
      "200 0.038999978452920914\n",
      "201 0.03769589588046074\n",
      "202 0.03643912449479103\n",
      "203 0.03522571548819542\n",
      "204 0.03405607491731644\n",
      "205 0.03292738273739815\n",
      "206 0.0318392775952816\n",
      "207 0.03078969195485115\n",
      "208 0.0297772828489542\n",
      "209 0.02880072221159935\n",
      "210 0.027858449146151543\n",
      "211 0.026949265971779823\n",
      "212 0.026071906089782715\n",
      "213 0.025224385783076286\n",
      "214 0.024407029151916504\n",
      "215 0.02361772209405899\n",
      "216 0.02285587042570114\n",
      "217 0.022120483219623566\n",
      "218 0.021410169079899788\n",
      "219 0.020724359899759293\n",
      "220 0.02006249688565731\n",
      "221 0.019422831013798714\n",
      "222 0.018805112689733505\n",
      "223 0.018208445981144905\n",
      "224 0.017632415518164635\n",
      "225 0.017075609415769577\n",
      "226 0.016537202522158623\n",
      "227 0.01601751148700714\n",
      "228 0.015514942817389965\n",
      "229 0.015029207803308964\n",
      "230 0.014559662900865078\n",
      "231 0.014105986803770065\n",
      "232 0.013667639344930649\n",
      "233 0.013243724592030048\n",
      "234 0.012833638116717339\n",
      "235 0.012437183409929276\n",
      "236 0.01205415278673172\n",
      "237 0.011683505959808826\n",
      "238 0.011325093917548656\n",
      "239 0.010978312231600285\n",
      "240 0.010643166489899158\n",
      "241 0.01031886599957943\n",
      "242 0.010004982352256775\n",
      "243 0.00970139168202877\n",
      "244 0.009407746605575085\n",
      "245 0.009123620577156544\n",
      "246 0.008848719298839569\n",
      "247 0.008582677692174911\n",
      "248 0.008325330913066864\n",
      "249 0.008076119236648083\n",
      "250 0.007834892719984055\n",
      "251 0.007601427845656872\n",
      "252 0.0073752691969275475\n",
      "253 0.007156442850828171\n",
      "254 0.0069446261040866375\n",
      "255 0.006739485543221235\n",
      "256 0.006540756206959486\n",
      "257 0.006348328664898872\n",
      "258 0.006161896511912346\n",
      "259 0.005981365218758583\n",
      "260 0.005806461907923222\n",
      "261 0.005636992864310741\n",
      "262 0.005472865886986256\n",
      "263 0.005313876550644636\n",
      "264 0.005159722175449133\n",
      "265 0.005010445602238178\n",
      "266 0.004865783732384443\n",
      "267 0.004725642502307892\n",
      "268 0.004589863121509552\n",
      "269 0.004458163864910603\n",
      "270 0.004330558702349663\n",
      "271 0.004206932615488768\n",
      "272 0.004087096080183983\n",
      "273 0.00397078413516283\n",
      "274 0.003858125302940607\n",
      "275 0.0037489060778170824\n",
      "276 0.0036429469473659992\n",
      "277 0.0035402216017246246\n",
      "278 0.0034406729973852634\n",
      "279 0.0033440962433815002\n",
      "280 0.0032504333648830652\n",
      "281 0.0031594717875123024\n",
      "282 0.003071306739002466\n",
      "283 0.0029857803601771593\n",
      "284 0.0029027555137872696\n",
      "285 0.002822259673848748\n",
      "286 0.0027441265992820263\n",
      "287 0.0026683351024985313\n",
      "288 0.0025948435068130493\n",
      "289 0.002523403847590089\n",
      "290 0.002454176777973771\n",
      "291 0.002386887324973941\n",
      "292 0.002321604872122407\n",
      "293 0.002258236287161708\n",
      "294 0.0021967259235680103\n",
      "295 0.002136991126462817\n",
      "296 0.002079072641208768\n",
      "297 0.0020227774512022734\n",
      "298 0.001968198921531439\n",
      "299 0.0019151153974235058\n",
      "300 0.0018635705346241593\n",
      "301 0.0018134997226297855\n",
      "302 0.0017649343935772777\n",
      "303 0.0017176936380565166\n",
      "304 0.0016718476545065641\n",
      "305 0.0016273155342787504\n",
      "306 0.00158402300439775\n",
      "307 0.0015419678529724479\n",
      "308 0.0015011024661362171\n",
      "309 0.001461406354792416\n",
      "310 0.0014228463405743241\n",
      "311 0.0013853635173290968\n",
      "312 0.0013489326229318976\n",
      "313 0.0013135623885318637\n",
      "314 0.0012791516492143273\n",
      "315 0.0012457109987735748\n",
      "316 0.0012132101692259312\n",
      "317 0.001181614468805492\n",
      "318 0.0011509050382301211\n",
      "319 0.0011210390366613865\n",
      "320 0.0010920139029622078\n",
      "321 0.0010637984378263354\n",
      "322 0.0010363487526774406\n",
      "323 0.0010096714831888676\n",
      "324 0.000983704929240048\n",
      "325 0.000958470453042537\n",
      "326 0.000933939591050148\n",
      "327 0.0009100563474930823\n",
      "328 0.0008868335862644017\n",
      "329 0.0008642528555355966\n",
      "330 0.0008422869723290205\n",
      "331 0.0008209023508243263\n",
      "332 0.0008001014357432723\n",
      "333 0.000779874506406486\n",
      "334 0.0007601820980198681\n",
      "335 0.0007410088437609375\n",
      "336 0.0007223691791296005\n",
      "337 0.0007042462239041924\n",
      "338 0.0006866132607683539\n",
      "339 0.0006694206385873258\n",
      "340 0.0006526968209072948\n",
      "341 0.0006364171276800334\n",
      "342 0.000620569393504411\n",
      "343 0.0006051403470337391\n",
      "344 0.0005901207914575934\n",
      "345 0.0005755118909291923\n",
      "346 0.0005612673121504486\n",
      "347 0.000547428207937628\n",
      "348 0.0005339362542144954\n",
      "349 0.0005208058864809573\n",
      "350 0.0005080040427856147\n",
      "351 0.0004955428885295987\n",
      "352 0.0004834120045416057\n",
      "353 0.00047160795656964183\n",
      "354 0.0004600933752954006\n",
      "355 0.00044888409320265055\n",
      "356 0.0004379568272270262\n",
      "357 0.0004273220256436616\n",
      "358 0.0004169500316493213\n",
      "359 0.00040685743442736566\n",
      "360 0.0003970195248257369\n",
      "361 0.00038744465564377606\n",
      "362 0.0003781075356528163\n",
      "363 0.0003690016455948353\n",
      "364 0.0003601371427066624\n",
      "365 0.0003514933050610125\n",
      "366 0.00034307799069210887\n",
      "367 0.00033486454049125314\n",
      "368 0.00032687102793715894\n",
      "369 0.0003190772549714893\n",
      "370 0.0003114806895609945\n",
      "371 0.00030407332815229893\n",
      "372 0.0002968504268210381\n",
      "373 0.00028982298681512475\n",
      "374 0.0002829601871781051\n",
      "375 0.0002762646181508899\n",
      "376 0.00026974474894814193\n",
      "377 0.0002633906260598451\n",
      "378 0.00025719439145177603\n",
      "379 0.00025114137679338455\n",
      "380 0.0002452479675412178\n",
      "381 0.00023950183822307736\n",
      "382 0.00023388993577100337\n",
      "383 0.00022842377074994147\n",
      "384 0.00022308804909698665\n",
      "385 0.00021788862068206072\n",
      "386 0.0002128189371433109\n",
      "387 0.00020786905952263623\n",
      "388 0.00020304160716477782\n",
      "389 0.00019833813712466508\n",
      "390 0.000193737490917556\n",
      "391 0.00018925603944808245\n",
      "392 0.00018488726345822215\n",
      "393 0.0001806225918699056\n",
      "394 0.000176462548552081\n",
      "395 0.00017239748558495194\n",
      "396 0.00016843178309500217\n",
      "397 0.00016456888988614082\n",
      "398 0.00016079377382993698\n",
      "399 0.00015711459855083376\n",
      "400 0.0001535219926154241\n",
      "401 0.00015001602878328413\n",
      "402 0.00014658930012956262\n",
      "403 0.00014325117808766663\n",
      "404 0.0001399897737428546\n",
      "405 0.00013680194388143718\n",
      "406 0.0001336986751994118\n",
      "407 0.00013066852989140898\n",
      "408 0.00012770533794537187\n",
      "409 0.00012481294106692076\n",
      "410 0.00012199103366583586\n",
      "411 0.00011923562124138698\n",
      "412 0.00011654622358037159\n",
      "413 0.00011392117448849604\n",
      "414 0.00011135658860439435\n",
      "415 0.00010885366646107286\n",
      "416 0.00010640994878485799\n",
      "417 0.00010402149200672284\n",
      "418 0.00010169277811655775\n",
      "419 9.94150759652257e-05\n",
      "420 9.719149238662794e-05\n",
      "421 9.501857857685536e-05\n",
      "422 9.289968875236809e-05\n",
      "423 9.082835458684713e-05\n",
      "424 8.880785026121885e-05\n",
      "425 8.682798215886578e-05\n",
      "426 8.489805622957647e-05\n",
      "427 8.301542402477935e-05\n",
      "428 8.116896060528234e-05\n",
      "429 7.93711660662666e-05\n",
      "430 7.761570304865018e-05\n",
      "431 7.589830056531355e-05\n",
      "432 7.422174530802295e-05\n",
      "433 7.258455298142508e-05\n",
      "434 7.09813175490126e-05\n",
      "435 6.941888568690047e-05\n",
      "436 6.789171311538666e-05\n",
      "437 6.639614730374888e-05\n",
      "438 6.493650289485231e-05\n",
      "439 6.351133197313175e-05\n",
      "440 6.211829168023542e-05\n",
      "441 6.0756025050068274e-05\n",
      "442 5.9427642554510385e-05\n",
      "443 5.8127443480771035e-05\n",
      "444 5.685329233529046e-05\n",
      "445 5.561368016060442e-05\n",
      "446 5.4398471547756344e-05\n",
      "447 5.3210089390631765e-05\n",
      "448 5.205137131270021e-05\n",
      "449 5.09175042679999e-05\n",
      "450 4.980879748472944e-05\n",
      "451 4.872894714935683e-05\n",
      "452 4.7669334890088066e-05\n",
      "453 4.6635381295345724e-05\n",
      "454 4.562117101158947e-05\n",
      "455 4.46342965005897e-05\n",
      "456 4.36685950262472e-05\n",
      "457 4.272385558579117e-05\n",
      "458 4.1799976315815e-05\n",
      "459 4.089680078322999e-05\n",
      "460 4.001392881036736e-05\n",
      "461 3.915035995305516e-05\n",
      "462 3.830526111414656e-05\n",
      "463 3.7480662285815924e-05\n",
      "464 3.667362761916593e-05\n",
      "465 3.5884950193576515e-05\n",
      "466 3.5113469493808225e-05\n",
      "467 3.4358989069005474e-05\n",
      "468 3.362101051607169e-05\n",
      "469 3.290009772172198e-05\n",
      "470 3.2194202503887936e-05\n",
      "471 3.150535121676512e-05\n",
      "472 3.082961120526306e-05\n",
      "473 3.0170911486493424e-05\n",
      "474 2.9524868295993656e-05\n",
      "475 2.8895494324387982e-05\n",
      "476 2.827672869898379e-05\n",
      "477 2.76764840236865e-05\n",
      "478 2.7085010515293106e-05\n",
      "479 2.650704118423164e-05\n",
      "480 2.5941923013306223e-05\n",
      "481 2.539026718295645e-05\n",
      "482 2.4849614419508725e-05\n",
      "483 2.432063229207415e-05\n",
      "484 2.3803888325346634e-05\n",
      "485 2.329762719455175e-05\n",
      "486 2.280267290188931e-05\n",
      "487 2.2320140487863682e-05\n",
      "488 2.1847043171874247e-05\n",
      "489 2.138356830982957e-05\n",
      "490 2.093013608828187e-05\n",
      "491 2.0487474102992564e-05\n",
      "492 2.0051971659995615e-05\n",
      "493 1.963087561307475e-05\n",
      "494 1.9214920030208305e-05\n",
      "495 1.88094509212533e-05\n",
      "496 1.8412032659398392e-05\n",
      "497 1.8022787116933614e-05\n",
      "498 1.7642512830207124e-05\n",
      "499 1.7271697288379073e-05\n"
     ]
    }
   ],
   "source": [
    "# Code in file nn/two_layer_net_module.py\n",
    "import torch\n",
    "\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "  def __init__(self, D_in, H, D_out):\n",
    "    \"\"\"\n",
    "    In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "    member variables.\n",
    "    \"\"\"\n",
    "    super(TwoLayerNet, self).__init__()\n",
    "    self.linear1 = torch.nn.Linear(D_in, H)\n",
    "    self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    In the forward function we accept a Tensor of input data and we must return\n",
    "    a Tensor of output data. We can use Modules defined in the constructor as\n",
    "    well as arbitrary (differentiable) operations on Tensors.\n",
    "    \"\"\"\n",
    "    h_relu = self.linear1(x).clamp(min=0)\n",
    "    y_pred = self.linear2(h_relu)\n",
    "    return y_pred\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# Construct our model by instantiating the class defined above.\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "for t in range(500):\n",
    "  # Forward pass: Compute predicted y by passing x to the model\n",
    "  y_pred = model(x)\n",
    "\n",
    "  # Compute and print loss\n",
    "  loss = loss_fn(y_pred, y)\n",
    "  print(t, loss.item())\n",
    "\n",
    "  # Zero gradients, perform a backward pass, and update the weights.\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T03:41:05.929767200Z",
     "start_time": "2024-02-15T03:41:05.619265Z"
    }
   },
   "id": "a8b74b9913a137ac",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Code in file nn/dynamic_net.py\n",
    "import random\n",
    "import torch\n",
    "\n",
    "class DynamicNet(torch.nn.Module):\n",
    "  def __init__(self, D_in, H, D_out):\n",
    "    \"\"\"\n",
    "    In the constructor we construct three nn.Linear instances that we will use\n",
    "    in the forward pass.\n",
    "    \"\"\"\n",
    "    super(DynamicNet, self).__init__()\n",
    "    self.input_linear = torch.nn.Linear(D_in, H)\n",
    "    self.middle_linear = torch.nn.Linear(H, H)\n",
    "    self.output_linear = torch.nn.Linear(H, D_out)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    For the forward pass of the model, we randomly choose either 0, 1, 2, or 3\n",
    "    and reuse the middle_linear Module that many times to compute hidden layer\n",
    "    representations.\n",
    "\n",
    "    Since each forward pass builds a dynamic computation graph, we can use normal\n",
    "    Python control-flow operators like loops or conditional statements when\n",
    "    defining the forward pass of the model.\n",
    "\n",
    "    Here we also see that it is perfectly safe to reuse the same Module many\n",
    "    times when defining a computational graph. This is a big improvement from Lua\n",
    "    Torch, where each Module could be used only once.\n",
    "    \"\"\"\n",
    "    h_relu = self.input_linear(x).clamp(min=0)\n",
    "    for _ in range(random.randint(0, 3)):\n",
    "      h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "    y_pred = self.output_linear(h_relu)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs.\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = DynamicNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "for t in range(500):\n",
    "  # Forward pass: Compute predicted y by passing x to the model\n",
    "  y_pred = model(x)\n",
    "\n",
    "  # Compute and print loss\n",
    "  loss = criterion(y_pred, y)\n",
    "  print(t, loss.item())\n",
    "\n",
    "  # Zero gradients, perform a backward pass, and update the weights.\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T03:41:01.285040800Z",
     "start_time": "2024-02-15T03:41:01.278109200Z"
    }
   },
   "id": "d0ba65122ed15a5b",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T03:41:02.816523900Z",
     "start_time": "2024-02-15T03:41:02.802669500Z"
    }
   },
   "id": "14cef5e5bb796c00",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "95af58af3db34098"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
