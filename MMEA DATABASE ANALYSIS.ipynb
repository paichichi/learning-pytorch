{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-09T08:52:39.360202Z",
     "start_time": "2024-04-09T08:52:35.453567Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Type\n",
      "human                           4495\n",
      "film                            1659\n",
      "association football club        608\n",
      "city                             330\n",
      "music genre                      328\n",
      "                                ... \n",
      "university college                 2\n",
      "university in France               2\n",
      "lieutenancy area of Scotland       2\n",
      "bicameral legislature              2\n",
      "dialect                            2\n",
      "Name: count, Length: 581, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'C:/Users/96446/Documents/GitHub/learning Pytorch/pytorch/FB15K_Updated.csv'\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "entity_type_counts = df['Entity Type'].value_counts()\n",
    "filtered_entity_type_counts = entity_type_counts[entity_type_counts >= 2]\n",
    "\n",
    "print(filtered_entity_type_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T08:21:10.825227Z",
     "start_time": "2024-04-09T08:21:10.782332Z"
    }
   },
   "id": "39de1d43b7dc04c5",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "pkl_file_path  = 'C:/Users\\96446\\Documents\\GitHub\\data\\mmkg\\pkls/FBDB15K_id_img_feature_dict.pkl'\n",
    "# 用pickle加载数据\n",
    "with open(pkl_file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# 检查数据的类型\n",
    "print(type(data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T15:01:59.088263Z",
     "start_time": "2024-04-09T15:01:58.566332Z"
    }
   },
   "id": "bec21f52d9c0de04",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([1.3076725, 1.2305019, 1.5317996, ..., 0.       , 2.080137 ,\n       0.       ], dtype=float32)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T15:02:22.642776Z",
     "start_time": "2024-04-09T15:02:22.639113Z"
    }
   },
   "id": "6fbf66c898415292",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\96446\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\96446\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\96446/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:42<00:00, 12.9MB/s] \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'image_path.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 41\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m embedding\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# Example usage:\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;66;03m# Replace 'image_path.jpg' with the path to an image file\u001B[39;00m\n\u001B[1;32m---> 41\u001B[0m embedding \u001B[38;5;241m=\u001B[39m image_to_embedding(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage_path.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28mprint\u001B[39m(embedding)\n",
      "Cell \u001B[1;32mIn[5], line 28\u001B[0m, in \u001B[0;36mimage_to_embedding\u001B[1;34m(image_path)\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mimage_to_embedding\u001B[39m(image_path):\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;66;03m# Load and transform the image\u001B[39;00m\n\u001B[1;32m---> 28\u001B[0m     image \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(image_path)\n\u001B[0;32m     29\u001B[0m     image \u001B[38;5;241m=\u001B[39m transform(image)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;66;03m# Get the embedding from the model\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3247\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(fp, mode, formats)\u001B[0m\n\u001B[0;32m   3244\u001B[0m     filename \u001B[38;5;241m=\u001B[39m fp\n\u001B[0;32m   3246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename:\n\u001B[1;32m-> 3247\u001B[0m     fp \u001B[38;5;241m=\u001B[39m builtins\u001B[38;5;241m.\u001B[39mopen(filename, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   3248\u001B[0m     exclusive_fp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   3250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'image_path.jpg'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImageFeatureMapper(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(ImageFeatureMapper, self).__init__()\n",
    "        # 定义图像特征映射到新空间的线性层\n",
    "        self.img_fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, img_features):\n",
    "        # 应用线性层并返回映射后的特征\n",
    "        img_emb = self.img_fc(img_features)\n",
    "        return img_emb\n",
    "\n",
    "input_dim = 4096  # 原始图像特征维度\n",
    "output_dim = 300  # 目标映射维度\n",
    "model = ImageFeatureMapper(input_dim, output_dim)\n",
    "\n",
    "# 假设我们有一个图像特征Tensor\n",
    "img_features = torch.randn(1, 4096)  # 示例输入，假设批大小为1\n",
    "\n",
    "# 将图像特征映射到300维空间\n",
    "img_emb = model(img_features)\n",
    "print(\"Mapped image features shape:\", img_emb.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T08:22:36.107926Z",
     "start_time": "2024-04-09T08:21:50.219548Z"
    }
   },
   "id": "cf402a084dac91d1",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.4554, -0.3123,  2.6431,  ...,  2.1465,  0.8970,  0.1708]])"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_features = torch.randn(1, 4096)\n",
    "img_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T15:57:00.859587Z",
     "start_time": "2024-04-09T15:57:00.851605Z"
    }
   },
   "id": "1eb42e0edbeffc09",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "vgg16_h5 = 'FB15K_ImageData.h5'\n",
    "f = h5py.File(vgg16_h5, 'r')\n",
    "vgg_feats = f[(\"FBIMG00001\")]\n",
    "\n",
    "vgg_feats_np = np.array(vgg_feats)\n",
    "print(vgg_feats_np)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T10:18:30.990673Z",
     "start_time": "2024-04-09T10:18:30.986072Z"
    }
   },
   "id": "d8800015c217fe1",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "image_index = 'FB15K/FB15K_ImageIndex.txt'\n",
    "result = {}\n",
    "with open(image_index, 'r') as fr:\n",
    "    for img_id in fr:\n",
    "        value = img_id.split()\n",
    "        result[value[0]] = value[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T11:47:04.008231Z",
     "start_time": "2024-04-09T11:47:03.996322Z"
    }
   },
   "id": "d7c792d01be73fa0",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[46], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m result[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mKeyError\u001B[0m: 0"
     ]
    }
   ],
   "source": [
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T11:47:38.570384Z",
     "start_time": "2024-04-09T11:47:38.546284Z"
    }
   },
   "id": "61ed35a7c3344664",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[70], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m     f \u001B[38;5;241m=\u001B[39m h5py\u001B[38;5;241m.\u001B[39mFile(vgg16_h5, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m     result2[key] \u001B[38;5;241m=\u001B[39m [np\u001B[38;5;241m.\u001B[39marray(f[(value)])]\n\u001B[1;32m----> 8\u001B[0m result2[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/m/01m4kpp\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "vgg16_h5 = 'FB15K_ImageData.h5'\n",
    "\n",
    "result2 = {}\n",
    "for key, value in result.items():\n",
    "    f = h5py.File(vgg16_h5, 'r')\n",
    "    result2[key] = [np.array(f[(value)])]\n",
    "    \n",
    "result2['/m/01m4kpp'][1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T15:57:35.976672Z",
     "start_time": "2024-04-09T15:57:28.448734Z"
    }
   },
   "id": "257e137a7aabb589",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n        0.5510511]], dtype=float32)"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2['/m/01m4kpp'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T15:57:42.585559Z",
     "start_time": "2024-04-09T15:57:42.577152Z"
    }
   },
   "id": "6adbd45b8d05b7e6",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3905f83519619de"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
